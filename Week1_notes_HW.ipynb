{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1: Introduction and Classification\n",
    "\n",
    "## Some glossary\n",
    "\n",
    "- Hard classifier is one that neccessitates no misclassification in its training/estimation. Soft classifier minimizes the weighted errors for misclassification, and the fitted model might have missclassified examples in the training data.\n",
    "- The loss function in classifiers can be weighted according to ad hoc importance associated to each class. E.g. the classification of toxic mushrooms vs edible mushrooms, loan qualities etc. \n",
    "- A higher relative weight pushes the boundary away from that particular class. Bear in mind that for soft classifiers as the relative weight get too large the boundary will be so far away that potentially includes data of other classes.\n",
    "- Structured data refers to datasets that can be stored in structured ways, e.g. numerical, string arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (Linear)\n",
    "\n",
    "Check [here](http://pyml.sourceforge.net/doc/howto.pdf) for a complete cover. A support vector is a vector that bounds the convex hull formed by the data points in a specific class. Notably, support vectors necessarily include data samples on the margin of the convex hull. The goal here is to find a set of separating hyperlines defined by a vector of coefficients (hence are parallel) that classifies the classes/minimizes (weighted) misclassification errors, and that the distance between the hyperplane and the nearest point from either group is maximized. \n",
    "\n",
    "SVMs are known to work well with data of high dimensional data, especially for $K>>N$. This is because the complexity is $O(KN^2)$. Before the rise of neural networks, (kernel) SVMs are the workhorse for pattern recognition.\n",
    "\n",
    "## Hard margin linear formulation\n",
    "\n",
    "The mathematical formulation for a __linear, hard margin__ SVM problem with binary classes $y_i \\in \\{-1,1\\}$ and data points $(x_1, x_2, \\ldots, x_n)$ where $x_i$ does not include the constant, is:\n",
    "\n",
    "\\begin{align*}\n",
    "&\\max_{a,b} D(a, b; x_1, x_2, \\ldots, x_n)\\\\\n",
    "&s.t. \\begin{cases}\n",
    "a^T x_i + b \\geq 1, & y_i = 1 \\\\\n",
    "a^T x_i + b \\leq -1, & y_i = -1 \\\\\n",
    "\\end{cases}\n",
    "\\end{align*}\n",
    "\n",
    "We note that the distance metric $D(a, b; x_1, x_2, \\ldots, x_n)$ is given by the distance between hyperplanes that are defined by $a^T x + b = 1$ and $a^T x + b = -1$. To derive this, note that the unit normal vector that is paralleled to the either plane is $\\frac{a}{\\Vert a \\Vert}$. Suppose $z$ is on $a^T x + b = -1$, then $z + t(\\frac{a}{\\Vert a \\Vert})$ where t is the distance between the planes will be on $a^T x + b = 1$.\n",
    "\n",
    "\\begin{align*}\n",
    "a^T\\big(z + t\\frac{a}{\\Vert a \\Vert}\\big) + b &= 1 \\\\\n",
    "(a^T z + b) + t \\frac{\\Vert a \\Vert^2}{\\Vert a \\Vert}  &= 1\\\\\n",
    "(-1) + t \\Vert a \\Vert &= 1\\\\\n",
    "t &= \\frac{2}{\\Vert a \\Vert}\n",
    "\\end{align*}\n",
    "\n",
    "Also noting that the constraints can be expressed as $(a^T x_i + b)y_i \\geq 1$ we express the SVM problem as:\n",
    "\n",
    "\\begin{align*}\n",
    "&\\min_{a,b} \\frac{1}{2}{\\Vert a \\Vert^2}\\\\\n",
    "&s.t. (a^T x_i + b)y_i \\geq 1 \\text{   } \\forall i\n",
    "\\end{align*}\n",
    "\n",
    "When we get SVM $(a,b)$ we can adjust \"zero\" to account for ad hoc penalty of misclassification. For example, if a hard margin SVM is defined by $a^T x + b = 0$. We can penalize misclassification into this class by adding a constant (absolute value < 1). Suppose we want to penalize $y=1$ , the event of loan repayment so that the bank does not overlend, we can add a constant, say $\\frac{1}{3}$ such the $y=1$ only if $a^T x + b \\geq \\frac{1}{3}$.\n",
    "\n",
    "## Soft margin linear formulation\n",
    "\n",
    "Check [here](https://towardsdatascience.com/support-vector-machines-soft-margin-formulation-and-kernel-trick-4c9729dc8efe) for more discussion. Recall that a SMV has a boundary defined by some discriminary function $f$, e.g. linear function $a^T x +b$ as we have been studying so far. The decision __boundary__ is defined by $f(x) = 0$, while the __margins__ are defined by $f(x) = \\pm 1$. A hard margin SVM requires that all points with $y = \\pm1$ lie within $f(x) = \\pm 1$, i.e. strict enforcement of $f(x_i) y_i \\geq 1$. A soft margin classifier, on the other hand, tolerates out-of-margin or even misclassified data points in the training process. We would prefer soft to hard margin classifier as the data itself might not be linearly separable, or to avoid overfitting when outliers are being forced to lie on the correct side, distorting the boundary. Instead of having margin inclusion as hard constraints, we now minimize both the classification error and the norm of weights. Recall that $(a^T x + b)y \\geq 1$ implies no error so the classification error can be expressed as $\\max\\{0, 1-(a^T x +b)y\\}$. Therefore, we express the soft margin linear SVM training problem as:\n",
    "\n",
    "\\begin{align*}\n",
    "&\\min_{a,b} \\sum_i \\max\\{0, 1-(a^T x_i +b)y_i\\} + \\frac{\\lambda}{2}\\Vert a \\Vert^2\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Here $\\lambda$ is the tradeoff between increasing the margin size and ensuring that the data points lie on the correct side of the margin. If we want to specify that importance/contribute vary across data points we can attribute weight $w_i$ to the $i$-th observation, as in:\n",
    "\n",
    "\\begin{align*}\n",
    "\\min_{a,b} \\sum_i w_i \\max\\{0, 1-(a^T x_i +b)y_i\\} + \\frac{1}{2}\\Vert a \\Vert^2\\\\\n",
    "\\end{align*}\n",
    "\n",
    "$\\lambda$ dissipated because when relative importance of $w_i$ vary it suffices to normalize importance of minimizing $\\Vert a \\Vert^2$ to 1. Some examples of weighing $w_i$ can be: assigned by $y_i$ if a particular outcome is rare or of different importance than the other. Data known to be boundary case and misclassified often, etc. Note that there is a Lagrange multiplier interpretation of $w_i$, by rewriting the problem as:\n",
    "\n",
    "\\begin{align*}\n",
    "\\min_{a,b} \\sum_i w_i \\big((a^T x_i +b)y_i-1\\big) + \\frac{1}{2}\\Vert a \\Vert^2\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Here $w_i = 0$ if $(a^T x_i +b)y_i - 1< 0$ and $w_i > 0$ otherwise. In other words, this complementary slackness implies a weight assignment determined by whether the data point lies on the correct region. In the literature, it is perhaps more common to express this in terms of slack variables $\\xi_i$ (check [here](https://math.stackexchange.com/questions/3133125/why-do-derivations-for-svm-not-consider-slack-variables-for-inequality-constrain) for a discussion on the equivalence):\n",
    "\n",
    "\\begin{align*}\n",
    "&\\min_{a,b} C\\sum_i \\xi_i + \\frac{1}{2}{\\Vert a \\Vert^2}\\\\\n",
    "&s.t. (a^T x_i + b)y_i \\geq 1 - \\xi_i, \\xi_i \\geq 0 \\text{   } \\forall i\n",
    "\\end{align*}\n",
    "\n",
    "The intuition on values of $\\xi_i$: 0 means within the margin, between 0-1 implies inside the margin, >1 means out of the margin. A smaller value of $C$ allows the classifier to ignore points close to the boundary, and increases the margin. \n",
    "\n",
    "## Need for feature engineering\n",
    "\n",
    "Models that are trained on distance metrics defined as functions of data values will require rescaling so that the distance will be unit-free. E.g. we would not want to have variations in large unit variables (e.g. SAT score) to dominate variables with smaller units (e.g. age). This will also apply to SVM. We can either compress the variables to a uniform (scaling) or normal (standardizing):\n",
    "1. Scaling usually applies to data known with bounds, e.g. RGS color intensities (0-255), SAT scores (200-800). It is also applied to neural network variables.\n",
    "2. Standardization applies to PCA and clustering.\n",
    "\n",
    "Usually, standardization is preferred, in general. Zero-mean and unit-variance make it easier to learn the weights. It also maintains useful information in outliers and makes the algorithm less sensitive to them (relative to min-max scaling). If unsure, it is always a good idea to try both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbor Classifier\n",
    "\n",
    "Notes from previous read of Python Machine Learning (Raschka):\n",
    "- Non-parametric classifier:\n",
    "    1. Choose a natural number k and a distance metric (Manhattan, Eucliean, Minkowski etc)\n",
    "    2. For each point to be classified, find the k nearest samples wrt chosen metric\n",
    "    3. Prediction of class labels by majority vote\n",
    "    4. As KNN are trained on distance concepts, features must be standardized to prevent bias against large scales.\n",
    "- Hyper-parameter: $k$ – overfitting-performance tradeoff, distance – needs to be meaningful.\n",
    "- Advantage: Simple to implement, handles multi-class cases, do well with enough representative data. Disadvantage: computationally expensive, the need to store data.\n",
    "- Disadvantage: it cannot be regularized, prone to curse of dimensionality and overfitting: if we would keep adding features, the dimensionality of the feature space grows, and becomes sparser and sparser. Due to this sparsity, it becomes much more easy to find a separable hyperplane because the likelihood that a training sample lies on the wrong side of the best hyperplane becomes infinitely small when the number of features becomes infinitely large (but sample size remains finite). Check [here](https://www.visiondummy.com/2014/04/curse-dimensionality-affect-classification/) for a detailed explanation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (Kernel)\n",
    "\n",
    "Linearly separability is rare in real life data set. In order to account for this in SVM, a straightforward workaround would be to map the feature space $X$ (or add non-linear terms) to a (potentially different dimension) transformed feature space $\\phi(X)$ that exhibits linear separability. The resulting separating function becomes $a^T \\phi(x) + b = 1$, which permits non-linearity in shape.\n",
    "\n",
    "Such transformation, despite intuitive, will be computationally expensive. For example, if $\\phi$ is the square operator, the number of terms increases linearly ($C^k_2$ cross terms). Fortunately, the kernel trick allows us to scale these transformed SVM efficiently. The kernel trick utilitzes two assumptions:\n",
    "\n",
    "1. The kernel function associated with mapping $\\phi$, $\\kappa(x,x') = \\phi^T(x)\\phi(x)$ can be evaluated easily. \n",
    "2. Optimal weight vector $a$ can be expressed as a linear combination of the training examples $\\sum_i \\alpha_i x_i$. In the transformed feature space, $a = \\sum_i \\alpha_i \\phi(x_i)$.\n",
    "\n",
    "The motivation is that the kernel function will be evaluated numerous times. \n",
    "\n",
    "\\begin{align*}\n",
    "&a^T \\phi(x) + b \\\\\n",
    "=&\\big(\\sum_i \\alpha_i \\phi(x_i)\\big)^T \\phi(x) +b\\\\\n",
    "=&\\sum_i \\alpha_i \\phi(x_i)^T\\phi(x) + b\\\\\n",
    "=&\\sum_i \\alpha_i \\kappa(x_i, x) + b\n",
    "\\end{align*}\n",
    "\n",
    "An example is the quadratic transformation on a 2-dimensional feature space. Suppose $\\phi(x) = [x_1^2, \\sqrt{2}x_1 x_2, x_2^2]$. The kernel function is:\n",
    "\n",
    "\\begin{align*}\n",
    "\\phi^T(x)\\phi(z) &= (x_1^2, \\sqrt{2}x_1 x_2, x_2^2)^T(z_1^2, \\sqrt{2}z_1 z_2, z_2^2)\\\\\n",
    "&= (x_1 z_1)^2 + 2 x_1 x_2 z_1 z_2 + (x_2 z_2)^2 \\\\\n",
    "&= (x^Tz)^2\n",
    "\\end{align*}\n",
    "\n",
    "Popular kernels include polynomial kernel, sigmoid, Gaussian kernel, etc ([more](https://data-flair.training/blogs/svm-kernel-functions/)). Note that even though the kernel trick is motivated by a mapping $\\phi$ we only need the kernel functions. For example, the Gaussian kernel given by $\\kappa(x,x') = \\exp(-\\gamma\\Vert x-x'\\Vert^2)$ does not have a mapping with explicit form $\\phi$ (check [here](https://stats.stackexchange.com/questions/69759/feature-map-for-the-gaussian-kernel) for more detailed discussion - turns out, the mapped feature space is of infinite dimension).\n",
    "\n",
    "Kernelized SVMs are reasonably powerful - before the age of neural networks, a quadratic kernel was able to outperform other models on the MNIST dataset.\n",
    "\n",
    "\n",
    "# SVM with Unbalanced Data\n",
    "\n",
    "Caution needs to be taken when applying classifiers to datasets with unbalanced classes (very rare occassions of a particular class label). First, there might not be sufficient examples to produce consistent fits. Even if there are sufficient examples in the entire dataset, information loss will be incurred in the train-test split if the process does not ensure stratified subsets of data. Finally, because one event (WLOG, assume the positive response) is rare, it will be hard to properly gauge performance - even a classifier that predicts purely the dominant labels will result in a low error rate. Mathematically,\n",
    "\n",
    "\\begin{align*}\n",
    "P(success) = P(success|+)P(+) + P(success|-)P(-)\n",
    "\\end{align*}\n",
    "\n",
    "A modified metric would be the balanced success rate defined as:\n",
    "\n",
    "\\begin{align*}\n",
    "\\tilde{P}(success) = \\frac{P(success|+)+P(success|-)}{2} \\triangleq BSR\n",
    "\\end{align*}\n",
    "\n",
    "The balanced error rate is defined as $1-BSR$. The concept on weighing success (thereby error) rates across classes is implemented in SVM through the hyper-parameter $C$. Instead of having a uniform contribution of error to the objective across all data points, we assign weights according to their classes: $C\\sum_i \\xi_i \\leftarrow C_+ \\sum_{I_+}\\xi_i + C_- \\sum_{I_-}\\xi_i$. Note that the total contribution will be $C_+n_+$ and $C_-n_-$ for both classes, equal contribution implies $\\frac{C_+}{C_-} = \\frac{n_-}{n_+}$. So we can have $C_\\pm = \\lambda n_\\mp$ where $\\lambda$ controls the overall magnitude for regularisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISYE 6501 Homework #1\n",
    "\n",
    "### Jeremy Wong | kwong301@gatech.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.1\n",
    "\n",
    "Describe a situation or problem from your job, everyday life, current events, etc., for which a classification model would be appropriate. List some (up to 5) predictors that you might use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer for 2.1\n",
    "\n",
    "A daily example where a classification model would be appropriate is the detection of suspicious user activities on network systems such as emails and cloud-based applications. To protect its users, each time a login activity is attempted the system will need to classify whether the current login is normal or suspicious. In the latter case, the system might require additional authentication (e.g. text messages) or even lock the account temporarily. Performance of this model will largely rely on its ability to model normal, realistic human behavior against fraudulent bots and malware, e.g. User behavior analytics (UBEA) models. If I were to build such a model, I will start with the following predictors:\n",
    "\n",
    "1. __User activity log__. Structured, cleaned user historical data can naturally arise from user activity logs in terms of lagged variables (up to creation of credentials) such as <u>lagged login timestamp</u>, <u>lagged location</u>, and <u>lagged success</u> etc. Intuitively, we want to screen out activities implying impossible travels and suspicious timings (e.g. attempts with gaps too regular / too short).\n",
    "2. __IP address__. For web systems, IP address can reveal information such as geographical location and internet service provider (ISP) which can help the model determine the status of the current login activity. At the minimum, it allows the system to determine if IP is from a known proxy pool.\n",
    "3. __useragent__. Includes software, operating system, and browser (and their versions). For example, when login activities are detected from a new device GMail will prompt an email to the user. Also, some systems (e.g. e-commerce platforms) would want to screen out login attempts from scripted agents such as `selenium`.\n",
    "4. __Geographical location__. For cell phone useragents.\n",
    "5. __Users' Manual Input__. It is becoming common that login detection involves multiple-step authentication including DUO or text temporary PIN, in which the user provided a real-time additional response so the model can classify legitimate human behavior better. One function that used to be popular is CAPTCHA, in which the user is prompted to repeat the text from a distorted image. With the popularity of deep-learning models with increasingly powerful pattern recognition power, it is becoming a dated approach.\n",
    "\n",
    "#### Reference\n",
    "\n",
    "- [A Statistical Approach to Measuring User Authenticity](https://theory.stanford.edu/~dfreeman/papers/ato-model.pdf)\n",
    "- [Microsoft cloud app UBEA documentation](https://docs.microsoft.com/en-us/cloud-app-security/tutorial-suspicious-activity)\n",
    "- [Google's reCAPTCHA test has been tricked by artificial intelligence](https://www.wired.co.uk/article/google-captcha-recaptcha)\n",
    "- [Integrating Python and kdb+ to detect suspicious logins](https://kx.com/blog/integrating-python-and-kdb-to-detect-suspicious-logins/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2\n",
    "\n",
    "The files `credit_card_data.txt` (without headers) and `credit_card_data-headers.txt` (with headers) contain a dataset with 654 data points, 6 continuous and 4 binary predictor variables.  It has anonymized credit card applications with a binary response variable (last column) indicating if the application was positive or negative. The dataset is the “Credit Approval Data Set” from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Credit+Approval) without the categorical variables and without data points that have missing values.\n",
    "\n",
    "1.\tUsing the support vector machine function ksvm contained in the R package kernlab, find a good classifier for this data. Show the equation of your classifier, and how well it classifies the data points in the full data set.  (Don’t worry about test/validation data yet; we’ll cover that topic soon.)\n",
    "\n",
    "2.\tYou are welcome, but not required, to try other (nonlinear) kernels as well; we’re not covering them in this course, but they can sometimes be useful and might provide better predictions than vanilladot.\n",
    "\n",
    "3.\tUsing the k-nearest-neighbors classification function kknn contained in the R kknn package, suggest a good value of k, and show how well it classifies that data points in the full data set.  Don’t forget to scale the data (scale=TRUE in kknn).\n",
    "\n",
    "__Some Tips__\n",
    "\n",
    "1. On `ksvm`\n",
    "\n",
    "    - You can use scaled=TRUE to get ksvm to scale the data as part of calculating a classifier.\n",
    "    - The term λ we used in the SVM lesson to trade off the two components of correctness and margin is called C in ksvm. One of the challenges of this homework is to find a value of C that works well; for many values of C, almost all predictions will be “yes” or almost all predictions will be “no”.\n",
    "    - ksvm does not directly return the coefficients a0 and a1…am. Instead, you need to do the last step of the calculation yourself. Here’s an example of the steps to take (assuming your data is stored in a matrix called data): \n",
    "\n",
    "    ```R\n",
    "    # call ksvm.  Vanilladot is a simple linear kernel.\n",
    "    model <- ksvm(data[,1:10],data[,11],type=”C-svc”,kernel=”vanilladot”,C=100,scaled=TRUE)\n",
    "    # calculate a1…am\n",
    "    a <- colSums(model@xmatrix[[1]] * model@coef[[1]])\n",
    "    a\n",
    "    # calculate a0\n",
    "    a0 <- –model@b\n",
    "    a0\n",
    "    # see what the model predicts\n",
    "    pred <- predict(model,data[,1:10])\n",
    "    pred\n",
    "    # see what fraction of the model’s predictions match the actual classification\n",
    "    sum(pred == data[,11]) / nrow(data)\n",
    "    ```\n",
    "2. On `kknn`\n",
    "\n",
    "    - You need to be a little careful. If you give it the whole data set to find the closest points to i, it’ll use i itself (which is in the data set) as one of the nearest neighbors. A helpful feature of R is the index –i, which means “all indices except i”.  For example, data[-i,] is all the data except for the ith data point. For our data file where the first 10 columns are predictors and the 11th column is the response, data[-i,11] is the response for all but the ith data point, and data[-i,1:10] are the predictors for all but the ith data point. (There are other, easier ways to get around this problem, but I want you to get practice doing some basic data manipulation and extraction, and maybe some looping too.)\n",
    "    - Note that kknn will read the responses as continuous, and return the fraction of the k closest responses that are 1 (rather than the most common response, 1 or 0).\n",
    "\n",
    "3. Other tips\n",
    "\n",
    "Hint: You might want to view the predictions your model makes; if C is too large or too small, they’ll almost all be the same (all zero or all one) and the predictive value of the model will be poor.  Even finding the right order of magnitude for C might take a little trial-and-error.\n",
    "\n",
    "Note: If you get the error “Error in vanilladot(length = 4, lambda = 0.5) : unused arguments (length = 4, lambda = 0.5)”, it means you need to convert data into matrix format:\n",
    "\n",
    "```R\n",
    "model <- ksvm(as.matrix(data[,1:10]),as.factor(data[,11]),type=”C-svc”,kernel=”vanilladot”,C=100,scaled=TRUE)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer for 2.2 (1)\n",
    "\n",
    "#### Data Inspection\n",
    "\n",
    "We apply the linear SVM (soft margin) on the credit card data, which has 10 numerical features encoded as `A*` and a class `R1` that we target to fit and predict. We see below that the ranges and scales for the features vary, so we need to perform some kind of scaling to the data (which will be internalized by `kernlab`). The class label `R1` is rather balanced with a roughly 9:11 ratio - this should render the dataset balanced and a single regularization parameter should suffice. \n",
    "\n",
    "We would probably want to __standardize__ the data instead of a min-max scaling, at least for variable `A15`. It has rather high variance and likely some outliers. Standardization allows the model to maintain useful information in outliers and makes the algorithm less sensitive to them relative to min-max scaling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T03:12:16.248829Z",
     "start_time": "2021-01-28T03:12:15.073Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'kknn' was built under R version 3.6.3\"\n",
      "Warning message:\n",
      "\"package 'matrixStats' was built under R version 3.6.3\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "       A1               A2              A3               A8        \n",
       " Min.   :0.0000   Min.   :13.75   Min.   : 0.000   Min.   : 0.000  \n",
       " 1st Qu.:0.0000   1st Qu.:22.58   1st Qu.: 1.040   1st Qu.: 0.165  \n",
       " Median :1.0000   Median :28.46   Median : 2.855   Median : 1.000  \n",
       " Mean   :0.6896   Mean   :31.58   Mean   : 4.831   Mean   : 2.242  \n",
       " 3rd Qu.:1.0000   3rd Qu.:38.25   3rd Qu.: 7.438   3rd Qu.: 2.615  \n",
       " Max.   :1.0000   Max.   :80.25   Max.   :28.000   Max.   :28.500  \n",
       "       A9              A10              A11              A12        \n",
       " Min.   :0.0000   Min.   :0.0000   Min.   : 0.000   Min.   :0.0000  \n",
       " 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.: 0.000   1st Qu.:0.0000  \n",
       " Median :1.0000   Median :1.0000   Median : 0.000   Median :1.0000  \n",
       " Mean   :0.5352   Mean   :0.5612   Mean   : 2.498   Mean   :0.5382  \n",
       " 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.: 3.000   3rd Qu.:1.0000  \n",
       " Max.   :1.0000   Max.   :1.0000   Max.   :67.000   Max.   :1.0000  \n",
       "      A14               A15               R1        \n",
       " Min.   :   0.00   Min.   :     0   Min.   :0.0000  \n",
       " 1st Qu.:  70.75   1st Qu.:     0   1st Qu.:0.0000  \n",
       " Median : 160.00   Median :     5   Median :0.0000  \n",
       " Mean   : 180.08   Mean   :  1013   Mean   :0.4526  \n",
       " 3rd Qu.: 271.00   3rd Qu.:   399   3rd Qu.:1.0000  \n",
       " Max.   :2000.00   Max.   :100000   Max.   :1.0000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(data.table)\n",
    "library(magrittr)\n",
    "library(kernlab)\n",
    "library(kknn)\n",
    "library(matrixStats)\n",
    "\n",
    "data <- fread('./hw1/credit_card_data-headers.txt')\n",
    "features <- names(data)[-length(data)] \n",
    "class <- names(data)[length(data)]\n",
    "\n",
    "data %>% summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM model outline\n",
    "\n",
    "We apply the model with liner kernel here, using the function `ksvm` under the package `kernlab`. In equation form, the SVM decision boundary is given by: $f(x) = a^T x + b$ where $a \\in \\mathbb{10}$ and $b \\in \\mathbb{R}$. The classification prediction will be given by sign of the discriminary function $f$, i.e. the hyperplane $f = 0$ will be the decision boundary. It is unlikely that the data can be separated linearly on a hard margin, so we opt to train a soft margin SVM. The objective for training is:\n",
    "\n",
    "\\begin{align*}\n",
    "\\min_{a,b} C\\sum_i w_i \\max\\{0, 1-(a^T x_i +b)y_i\\} + \\frac{1}{2}\\Vert a \\Vert^2\\\\\n",
    "\\end{align*}\n",
    "\n",
    "The margins of the SVM for each class are given by the regions $a^T x + b = \\pm 1$, respectively. A soft margin SVM, as per the above equation, does not stricly require that all training data lie within the correct margins: the space between the two hyperplanes is maximized, while keeping _most_ data points within the correct margin implied by their labels. This trade off is calibrated by the hyper parameter $C$ which implicitly controls the magnitudes for the weights $w_i$. A large $C$ imposes high penalty in violating the margin constraint, and therefore will lead to smaller margins. On the other hand, a small $C$ imposes low penalty and tends to put less weights on the boundary cases to expand the margins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation\n",
    "\n",
    "Some context of function arguments used in `ksvm`:\n",
    "- `type=\"C-svc\"` specifies that the SVM is to be used for classification (hence \"svc\" instead of \"svr\"). Moreover, the regularized with a constant $C$ that specifies cost of violation as in the above equation (as opposed to the percentage of support vectors, $\\nu \\in [0,1]$ in other formulations, see [here](https://www.quora.com/What-is-the-difference-between-C-SVM-and-nu-SVM) for discussion).\n",
    "- `kernel` specifies the kernel function function used in the SVC, which decides the shape of the decision boundary $f = 0$.\n",
    "- `C` is the regularization that determines the cost of classification constraints. High values of $C$ assigns more importance on classifying the data within the margin (hence typically results in a narrower margin length). Since the goal of this exercise is to explore the performance of fitted (optimized) SVM in terms of prediction, we set an arbitrarily high value of $C$, 100 to start with.\n",
    "- `scale=TRUE` dictates that non-binary data be __standardized__ to zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T03:12:18.620881Z",
     "start_time": "2021-01-28T03:12:15.094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting default kernel parameters  \n",
      "Support Vector Machine object of class \"ksvm\" \n",
      "\n",
      "SV type: C-svc  (classification) \n",
      " parameter : cost C = 100 \n",
      "\n",
      "Linear (vanilla) kernel function. \n",
      "\n",
      "Number of Support Vectors : 189 \n",
      "\n",
      "Objective Function Value : -17887.92 \n",
      "Training error : 0.136086 \n"
     ]
    }
   ],
   "source": [
    "# apply and train model\n",
    "feat_mat = data[, features, with=FALSE] %>% as.matrix\n",
    "cla_mat = data[, class, with=FALSE] %>% as.matrix\n",
    "\n",
    "model <- ksvm(feat_mat, cla_mat, type=\"C-svc\", kernel=\"vanilladot\", C=100, scale=TRUE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagnostics\n",
    "\n",
    "We see from the above model output that the overall error rate is about 13.61%, or 86.39% accuracy. To assess model performance for each label, we computed the confusion matrix below, in terms of counts and percentages. It appears that the SVM is better at identifying 1-labelled data points - the success rates for 0 and 1 are 79.89% and 94.25%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T03:12:18.845269Z",
     "start_time": "2021-01-28T03:12:15.104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   R1   0   1\n",
      "1:  0 286  72\n",
      "2:  1  17 279\n"
     ]
    }
   ],
   "source": [
    "# check in-sample fit\n",
    "data[, 'R1_pred' := predict(model, feat_mat)]\n",
    "\n",
    "# in-sample confusion matrix\n",
    "conf_mat <- data[, .N, by=.(R1, R1_pred)] %>% dcast(., R1~R1_pred, value.var=\"N\")\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T03:12:18.870214Z",
     "start_time": "2021-01-28T03:12:15.106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   R1          0         1\n",
      "1:  0 0.79888268 0.2011173\n",
      "2:  1 0.05743243 0.9425676\n"
     ]
    }
   ],
   "source": [
    "# normalize in terms of %\n",
    "conf_mat[, 2:3] = conf_mat[, 2:3] / conf_mat[, rowSums(.SD), .SDcols=c(2,3)]\n",
    "print(conf_mat)\n",
    "\n",
    "# alternative way to code conf_mat\n",
    "# conf_mat <- table(data[, R1], predict(model, feat_mat))\n",
    "# conf_mat <- conf_mat / rowSums(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importance of variables\n",
    "\n",
    "Note that `model@coef` gives the weights for each data point $\\alpha_i$ in the fitted coefficients $a = \\sum_i \\alpha_i x_i$, where $x_i$ are scaled data points stored in `model@xmatrix`. Check [here](https://www.rdocumentation.org/packages/kernlab/versions/0.9-29/topics/ksvm-class) for a complete list of attributes and methods for the `ksvm` class. So to find the final cofficients for each feature we just need to compute the sum of `model@coef` $\\times$ `model@xmatrix` across all samples (column sum). It appears that `A9` and `A15` are the most determining features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T03:12:18.938986Z",
     "start_time": "2021-01-28T03:12:15.117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.table: 1 × 10</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>A1</th><th scope=col>A2</th><th scope=col>A3</th><th scope=col>A8</th><th scope=col>A9</th><th scope=col>A10</th><th scope=col>A11</th><th scope=col>A12</th><th scope=col>A14</th><th scope=col>A15</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>-0.001006535</td><td>-0.001172905</td><td>-0.001626197</td><td>0.00300642</td><td>1.004941</td><td>-0.002825943</td><td>0.0002600295</td><td>-0.0005349551</td><td>-0.001228376</td><td>0.1063634</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 1 × 10\n",
       "\\begin{tabular}{llllllllll}\n",
       " A1 & A2 & A3 & A8 & A9 & A10 & A11 & A12 & A14 & A15\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t -0.001006535 & -0.001172905 & -0.001626197 & 0.00300642 & 1.004941 & -0.002825943 & 0.0002600295 & -0.0005349551 & -0.001228376 & 0.1063634\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 1 × 10\n",
       "\n",
       "| A1 &lt;dbl&gt; | A2 &lt;dbl&gt; | A3 &lt;dbl&gt; | A8 &lt;dbl&gt; | A9 &lt;dbl&gt; | A10 &lt;dbl&gt; | A11 &lt;dbl&gt; | A12 &lt;dbl&gt; | A14 &lt;dbl&gt; | A15 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| -0.001006535 | -0.001172905 | -0.001626197 | 0.00300642 | 1.004941 | -0.002825943 | 0.0002600295 | -0.0005349551 | -0.001228376 | 0.1063634 |\n",
       "\n"
      ],
      "text/plain": [
       "  A1           A2           A3           A8         A9       A10         \n",
       "1 -0.001006535 -0.001172905 -0.001626197 0.00300642 1.004941 -0.002825943\n",
       "  A11          A12           A14          A15      \n",
       "1 0.0002600295 -0.0005349551 -0.001228376 0.1063634"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(model@coef[[1]]  *  model@xmatrix[[1]]) %>% colSums %>% as.list %>% as.data.table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimenting with regularization constant `C`\n",
    "\n",
    "Perhaps we haven't stressed the importance of no violation. We'll increase the cost of violation with higher values of `C` and experiment with a much larger value of 10000. As seen below the accurary did not increase. We know that at some point the training accuracy will stop improving even if $C$ is further increased because beyond that point the optimizer is already ignoring the importance of maximizing the margin, effectively. It seems that an error around 13%-14% is as good as we can get from a linear kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T03:12:32.252558Z",
     "start_time": "2021-01-28T03:12:15.125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting default kernel parameters  \n",
      "Support Vector Machine object of class \"ksvm\" \n",
      "\n",
      "SV type: C-svc  (classification) \n",
      " parameter : cost C = 10000 \n",
      "\n",
      "Linear (vanilla) kernel function. \n",
      "\n",
      "Number of Support Vectors : 284 \n",
      "\n",
      "Objective Function Value : -1721868 \n",
      "Training error : 0.137615 \n"
     ]
    }
   ],
   "source": [
    "model <- ksvm(feat_mat, cla_mat, type=\"C-svc\", kernel=\"vanilladot\", C=10000, scale=TRUE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer for 2.2 (2)\n",
    "\n",
    "#### Implementing different kernels\n",
    "\n",
    "We proceed to try out all other kernels made available under `ksvm`, including:\n",
    "\n",
    "- `rbfdot`: Radial Basis kernel \"Gaussian\"\n",
    "- `polydot` Polynomial kernel\n",
    "- `vanilladot` Linear kernel\n",
    "- `tanhdot` Hyperbolic tangent kernel\n",
    "- `laplacedot` Laplacian kernel\n",
    "- `besseldot` Bessel kernel\n",
    "- `anovadot` ANOVA RBF kernel\n",
    "- `splinedot` Spline kernel\n",
    "- `stringdot` String kernel\n",
    "\n",
    "In each of the kernel there's a respecting kernel-specific `kpar` to be passed. I experimented by taking values from arbitrary intervals. For simplicity with kernels requiring multiple `kpar` to tune, including Bessel, ANOVA, and string we'll just use the default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T03:12:41.796754Z",
     "start_time": "2021-01-28T03:12:15.135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n"
     ]
    }
   ],
   "source": [
    "model_error = list()\n",
    "\n",
    "# rbfdot\n",
    "sigma <- c(.01, .1, .5, 1, 2, 5, 10, 25, 50, 100)\n",
    "rbf_error = list()\n",
    "for (x in sigma) {\n",
    "    model <- ksvm(feat_mat, cla_mat, type=\"C-svc\", kernel=\"rbfdot\", kpar=list(sigma=x), C=100, scale=TRUE)\n",
    "    rbf_error[[x %>% toString]] <- error(model)\n",
    "}\n",
    "model_error[['rbf']] <- rbf_error %>% unlist %>% min\n",
    "rbf_sigma <- which.min(rbf_error) %>% names()\n",
    "\n",
    "# polydot\n",
    "degree <- c(2,3,4,5,6,7)\n",
    "poly_error = list()\n",
    "for (x in degree) {\n",
    "    model <- ksvm(feat_mat, cla_mat, type=\"C-svc\", kernel=\"polydot\", kpar=list(degree=x), C=100, scale=TRUE)\n",
    "    poly_error[[x %>% toString]] <- error(model)\n",
    "}\n",
    "model_error[['poly']] <- poly_error %>% unlist %>% min\n",
    "poly_deg <- which.min(poly_error) %>% names()\n",
    "\n",
    "# tanhdot\n",
    "scale <- c(.01, .1, .5, 1, 2, 5, 10, 25, 50, 100)\n",
    "tanh_error = list()\n",
    "for (x in degree) {\n",
    "    model <- ksvm(feat_mat, cla_mat, type=\"C-svc\", kernel=\"tanhdot\", kpar=list(scale=x), C=100, scale=TRUE)\n",
    "    tanh_error[[x %>% toString]] <- error(model)\n",
    "}\n",
    "model_error[['tanh']] <- tanh_error %>% unlist %>% min\n",
    "tanh_scale <- which.min(tanh_error) %>% names()\n",
    "\n",
    "# laplacedot\n",
    "model <- ksvm(feat_mat, cla_mat, type=\"C-svc\", kernel=\"laplacedot\", C=100, scale=TRUE)\n",
    "model_error[['laplace']] <- error(model)\n",
    "\n",
    "# besseldot\n",
    "model <- ksvm(feat_mat, cla_mat, type=\"C-svc\", kernel=\"besseldot\", C=100, scale=TRUE)\n",
    "model_error[['bessel']] <- error(model)\n",
    "\n",
    "# anovadot\n",
    "model <- ksvm(feat_mat, cla_mat, type=\"C-svc\", kernel=\"anovadot\", C=100, scale=TRUE)\n",
    "model_error[['anova']] <- error(model)\n",
    "\n",
    "# splinedot\n",
    "model <- ksvm(feat_mat, cla_mat, type=\"C-svc\", kernel=\"anovadot\", C=100, scale=TRUE)\n",
    "model_error[['spline']] <- error(model)\n",
    "\n",
    "model_error <- model_error %>% setDT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Accuracy Comparison\n",
    "\n",
    "We compare the best error rates for each kernel. We see here that non-linear kernels tend to perform better than vanilladot, with perfect fits in RBF, laplace, and polynomial. However it is acknowledged that perfect fit does not equate best model - might just be overfitting the data. This can be seen observing that the polynomial kernel started attaining perfect fit when degree is larger than or equal to 5 - when the shape of decision boundary can take more arbitrary shapes that perfectly separate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T03:12:41.823681Z",
     "start_time": "2021-01-28T03:12:15.144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rbf poly     tanh laplace     bessel      anova     spline\n",
      "1:   0    0 0.266055       0 0.07492355 0.09327217 0.09327217\n"
     ]
    }
   ],
   "source": [
    "print(model_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T03:12:41.842630Z",
     "start_time": "2021-01-28T03:12:15.146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          2           3           4           5           6           7 \n",
      "0.107033639 0.009174312 0.001529052 0.000000000 0.000000000 0.000000000 \n"
     ]
    }
   ],
   "source": [
    "print(poly_error %>% unlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer for 2.2 (3)\n",
    "\n",
    "#### Outline of KNN\n",
    "\n",
    "Instead of outlining a KNN classifier with mathematical syntax, we list the algorithm steps as follows:\n",
    "1. Choose a natural number $k$ and a distance metric (Manhattan, Eucliean, generalized Minkowski etc). \tTo prevent bias against large scales, features must be standardized or scaled.\n",
    "2. For each point to be classified, find the k nearest samples with respect to the chosen metric.\n",
    "3. Prediction of class labels by majority vote.\n",
    "\n",
    "#### Implementation\n",
    "\n",
    "We train a KNN classifier with `kknn` function defined under the `kknn` package. Some context of function arguments:\n",
    "- `distance`: Minkowski distance parameter, determines how distance is defined.\n",
    "- `k`: size of neighborhood $K$.\n",
    "- `kernel`: kernel function to weigh neighbors according to their distances. `rectangular` means the regular unweighted KNN.\n",
    "\n",
    "Also note that `kknn` treats `R1` as a continuous variables and returns the predicted expected value of `R1`, instead of discrete classification. Because `R1` is binary this is simply the fraction of points with 1 label that are within the $k$ neighborhood. Recall that predication of class labels are determined by majority vote, so we will just need to round them. We consider `distance` equals 1 and 2, which correspond to the Manhattan and Euclidean distances respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 80-20 Train-Test Split\n",
    "\n",
    "As a starter, we take 80-20 train-test fit. Overall, the accuracy are increasing with $K$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T03:12:43.993841Z",
     "start_time": "2021-01-28T03:12:15.164Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: 'ggplot2'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:kernlab':\n",
      "\n",
      "    alpha\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAASwCAMAAADc/0P9AAAAe1BMVEUAAAAzMzNNTU1oaGh1\n1dd5uLh52Nt8fHx9vb1/3+GDg4OMjIyVlZWampqjo6Onp6evr6+ysrK5ubm9vb3BwcHHx8fJ\nycnQ0NDR0dHY2NjZ2dne3t7h4eHk5OTp6enq6urr6+vv7+/w8PDysKzy8vL1tK/19fX7urb/\n//9jonFXAAAACXBIWXMAABJ0AAASdAHeZh94AAAgAElEQVR4nO2960LbSNcG60/A5g0kIZkc\nyBCGENg78f1f4bbUPujQOmu11yOqfkyILZdXG7rGFoZstgAAImzOPQAAwFAIFgDIQLAAQAaC\nBQAyECwAkIFgAYAMBAsAZCBYACADwQIAGQgWAMhAsHTY7Dj97T7/6/X+4s1t/aD4pQDa8GWs\nQ6U6x16FNG0eawfFLwXQhi9jHcrVOfVqn6bb2kHxSwG04ctYh1J17k692qfp8GSqGqz6pQDa\n8GWsw6k65V4d0nRbPSh+KYA2fBnrcKxOpVfFxdnxyVQ5WM1LAbThy1iHQ3WKXt1VLv5yvKQc\nrOalJV4+3xbdu3s8XvR4d9F9SUlz/LD44HO2ufg8yLr78GJ/xQUVhbHwFaPDvhG1XoWL8ydT\nL6WDWi49cb85cnDd9l7SFqy8jJtvg6wfdh88FVc87T76sNBDA28FgqVDaETRq0394uOTqUqw\nGpceediUuC8uykqXfIhf0has/MDbYdb7fdq222/HYwCGQrB0KBqxf8LypXbx8clUJViNS49c\n7yqT1+Lxet+aQnxxn7+oO9SmeUlbsPYJGmQ9XFNcZfAowarhS0aHfMtfH56tvFQu3h6fTFWD\nVb/0yNPni3BO6WV/1ePmeHIpb8t17JLWYN0NtxavCQ835BUhjIRg6XBoVXFe+7Zy8fb4ZKoa\nrPqlLdZteKW5f4H2cnF3/xK7pDVYD8OtxWvC/PgHXhHCeAiWDsdzQ0+VSOzbsH8yVQtW7dIa\nLw+fr/dXXVeetW2jl7QG67FyVKe1uEH+jOyOV4QwHr5mdDj0Kry8uihfnP8ZnkzVglW7tMTT\nl9P377axpEVu0xasEdbiNWE++wWvCGE8BEuHY69Chr6ULs7/DE+m6sGqXnrk6XgybMlgDbCG\n14RPxbNEXhHCWAiWDqdeFZs+ezldnP+Zn+jOGsGqXnrgqXi3QXb75eGlNS3jgzXEGi78UoR0\nwmMAbxy+aHQo7/78hdeH2sX5WaEv9WBVLz2Qf6vu+ql88/y5UfVUVPOS0gQvsWANsYbDrvNr\neEUIoyFYOpSrk79foP5zgsWTqUawKpc2VYfy5F3bv5uq9F3C6iXFzcLzuodYsIZYt+Hp4Quv\nCGEKBEuHSnXyFFzULr47nTxqubSsejlduw0FzCrq5iXFT/+FzNy2BavPuj+Od43CJPiq0aFa\nnezw5KX2vKYRrPKlB/KXate7J2gPt8erhrzTPY9O/lb2h+uTsaQeZN2Gl468IoQpECwdqtX5\ndnjyUrr4Lhas8qUHSj+knJOfd3op/9Rf8bbU5iWPx7+eXmSW1IOsx+N4RQjjIVg61KqTvz6r\n/djNSzRYpUuPfD5E5MOXQzteGr+toXnJl0OvnmLBGmbd34avPJgAXzY61Hb54bx7+eLTr3KI\nX1q69Yfdc5+Lu8fiDVH7pz4PH/II3n5+Oh7VuKS42e23tjeODrMWrwl5RQgTIFiQntKPGAKM\ngWBBcl54RQgT4esGUvNyXTmhBTAcggVpKX0LEWAsBAvSsuE9DTAdggVpudhssg+Nny8EGATB\nAgAZCBYAyECwAEAGggUAMhAsAJCBYAGADAQLAGQgWAAgg12wnltovWI6yysVjBJDsuzUSrMN\n7QOCJWuUGJJlp1aabWgfECxZo8SQLDu10mxD+4BgyRolhmTZqZVmG9oHBEvWKDEky06tNNvQ\nPiBYskaJIVl2aqXZhvYBwZI1SgzJslMrzTa0DwiWrFFiSJadWmm2oX1AsGSNEkOy7NRKsw3t\nA4Ila5QYkmWnVpptaB8QLFmjxJAsO7XSbEP7gGDJGiWGZNmplWYb2gcES9YoMSTLTq0029A+\nIFiyRokhWXZqpdmG9gHBkjVKDMmyUyvNNrQPCJasUWJIlp1aabahfUCwZI0SQ7Ls1EqzDe0D\ngiVrlBiSZadWmm1oHxAsWaPEkCw7tdJsQ/uAYMkaJYZk2amVZhvaBwRL1igxJMtOrTTb0D4g\nWLJGiSFZdmql2Yb2AcGSNUoMybJTK802tA8IlqxRYkiWnVpptqF9QLBkjRJDsuzUSrMN7QOC\nJWuUGJJlp1aabWgfECxZo8SQLDu10mxD+4BgyRolhmTZqZVmG9oHBEvWKDEky06tNNvQPiBY\nskaJIVl2aqXZhvYBwZI1SgzJslMrzTa0DwiWrFFiSJadWmm2oX1AsGSNEkOy7NRKsw3tA4Il\na5QYkmWnVpptaB8QLFmjxJAsO7XSbEP7gGDJGiWGZNmplWYb2gcES9YoMSTLTq0029A+IFiy\nRokhWXZqpdmG9gHBkjVKDMmyUyvNNrQPCJasUWJIlp1aabahfUCwZI0SQ7Ls1EqzDe0DgiVr\nlBiSZadWmm1oHxAsWaPEkCw7tdJsQ/uAYMkaJYZk2amVZhvaBwRL1igxJMtOrTTb0D4gWLJG\niSFZdmql2Yb2AcGSNUoMybJTK802tA8IlqxRYkiWnVpptqF9QLBkjRJDsuzUSrMN7QOClcj4\nd3GjxLLf6GebYFlBsNIYX/++Lq1UWPYb/WwTLDMIVhojwXKsVDASrADBSmMkWI6VCkaCFSBY\naYwEy7FSwUiwAgQrjZFgOVYqGAlWgGClMRIsx0oFI8EKEKw0RoLlWKlgJFgBgpXGSLAcKxWM\nBCtAsNIYCZZjpYKRYAUIVhrjLliLF0tg2W/0s02wzLALFpT4m3PuIQDk4RlWEuMrz7AcKxWM\nPMMKEKwkRoLlWalgJFgBgpXESLA8KxWMBCtAsJIYCZZnpYKRYAUIVhIjwfKsVDASrADBSmIk\nWJ6VCkaCFSBYSYwEy7NSwUiwAgQriZFgeVYqGAlWgGAlMRIsz0oFI8EKEKwkRoLlWalgJFgB\ngpXESLA8KxWMBCtAsJIYCZZnpYKRYAUIVhIjwfKsVDASrADBSmIkWJ6VCkaCFSBYSYwEy7NS\nwUiwAgQriZFgeVYqGAlWgGAlMRbBWrpY/pf9Rj/bBMsOgpXESLA8KxWMBCtAsFIYd7HaEiy3\nSgUjwQoQrBRGguVaqWAkWAGClcJIsFwrFYwEK0CwUhgJlmulgpFgBQhWCiPBcq1UMBKsAMFK\nYSRYrpUKRoIVIFgpjATLtVLBSLACBCuFkWC5VioYCVaAYKUwEizXSgUjwQoQrBRGguVaqWAk\nWAGClcJIsFwrFYwEK0CwUhgJlmulgpFgBQhWCiPBcq1UMBKsAMFKYSRYrpUKRoIVIFgpjATL\ntVLBSLACBCuFkWC5VioYCVaAYKUw5sF6XrxY7pdtYpQYkmBZQbBSGAmWa6WCkWAFCFYKI8Fy\nrVQwEqwAwUpgzFNFsPwqFYwEK0CwEhgJlm+lgpFgBQhWAiPB8q1UMBKsAMFKYCRYvpUKRoIV\nIFgJjATLt1LBSLACBCuBkWD5VioYCVaAYCUwEizfSgUjwQoQrARGguVbqWAkWAGClcBIsHwr\nFYwEK0CwEhgJlm+lgpFgBQhWAiPB8q1UMBKsAMFKYCRYvpUKRoIVIFgJjATLt1LBSLACBCuB\nkWD5VioYCVaAYCUwEizfSgUjwQoQrATGEKzFi+V92TZGiSEJlhUEK4GRYPlWKhgJVoBgJTAS\nLN9KBSPBChCsBEaC5VupYCRYAYJlbyxCRbD8KhWMBCtAsOyNBMu5UsFIsAIEy95IsJwrFYwE\nK0Cw7I0Ey7lSwUiwAgTL3kiwnCsVjAQrQLDsjQTLuVLBSLACBMveSLCcKxWMBCtAsOyNBMu5\nUsFIsAIEy95IsJwrFYwEK0Cw7I0Ey7lSwUiwAgTL3kiwnCsVjAQrQLDsjQTLuVLBSLACBMve\nSLCcKxWMBCtAsOyNh2AtXSznyzYySgxJsKwgWPZGguVcqWAkWAGCZW8kWM6VCkaCFSBY9kaC\n5VypYCRYAYJlbyRYzpUKRoIVIFjmxpApguVXqWAkWAGCZW4kWN6VCkaCFSBY5kaC5V2pYCRY\nAYJlbiRY3pUKRoIVIFjmRoLlXalgJFgBgmVuJFjelQpGghUgWOZGguVdqWAkWAGCZW4kWN6V\nCkaCFSBY5kaC5V2pYCRYAYJlbiRY3pUKRoIVIFjmRoLlXalgJFgBgmVuJFjelQpGghUgWOZG\nguVdqWAkWAGCZW48BWvhYvletpVRYkiCZQXBMjcSLO9KBSPBChAscyPB8q5UMBKsAMEyNxIs\n70oFI8EKECxzI8HyrlQwEqwAwTI3EizvSgUjwQoQLGvjPlIEy69SwUiwAgTL2kiw3CsVjAQr\nQLCsjQTLvVLBSLACBMvaSLDcKxWMBCtAsKyNBMu9UsFIsAIEy9pIsNwrFYwEK0CwrI0Ey71S\nwUiwAgTL2kiw3CsVjAQrQLCsjQTLvVLBSLACBMvaSLDcKxWMBCtAsKyNBMu9UsFIsAIEy9pI\nsNwrFYwEK0CwrI3lYC1bLNfLNjNKDEmwrCBY1kaC5V6pYCRYAYJlbSRY7pUKRoIVIFjWRoLl\nXqlgJFgBgmVtJFjulQpGghUgWNZGguVeqWAkWAGCZW0kWO6VCkaCFSBYxsZDogiWX6WCkWAF\nCJaxkWD5VyoYCVaAYBkbCZZ/pYKRYAUIlrGRYPlXKhgJVoBgGRsJln+lgpFgBQiWsZFg+Vcq\nGAlWgGAZGwmWf6WCkWAFCJaxkWD5VyoYCVaAYBkbCZZ/pYKRYAUIlrGRYPlXKhgJVoBgGRsJ\nln+lgpFgBQiWsbEarEWL5XnZdkaJIQmWFQTL2Eiw/CsVjAQrQLCMjQTLv1LBSLACBMvYSLD8\nKxWMBCtAsIyNBMu/UsFIsAIEy9hIsPwrFYwEK0CwjI0Ey79SwUiwAgTL2Eiw/CsVjAQrQLBs\njcdAESy/SgUjwQoQLFsjwRJQKhgJVoBg2RoJloBSwUiwAgTL1kiwBJQKRoIVIFi2RoIloFQw\nEqwAwbI1EiwBpYKRYAUIlq2RYAkoFYwEK0CwbI0ES0CpYCRYAYJlaxwerPEhc7xsQ6PEkATL\nCoJlaxwcrAlPvRwv29AoMSTBsoJg2RrrwWoNE8E6n1LBSLACI4L1432WffxRv+SfXy3Xzn3g\nR+D4C45gCSgVjAQrMDxYn7KCT6dLvoZLfsavnfvAj8DxFxzBElAqGAlWYHCwfmU3uzL9vMl+\nHy75md38t93+/pj9iV1LsAoIloBSwUiwAoOD9T37N//jZ3Z82fcx+y//47/se+xaglUwNFiv\nBOt8SgUjwQoMDtanLJysOr3qy7Lt8ZLmtQSrgGAJKBWMBCswOFg3hzzdHC45BiuLXUuwCsYE\na2yxHC/b0CgxJMGyYnCwynkKvA/Pqn7ml9Su/b8di40ozd+/f3suOF4cvwIATswI1o/s4+/i\nRHszWDlz/08xAsf/h+QZloBSwcgzrMCMYG0/Fu9k+Eqw2jlViGD5VSoYCVZgxjms3XOsm+z9\nj232kXNYbRCsxY0SQxIsK8Z+l/BX+b2hBf9l/0SvnfvAj8DvFxzBWtwoMSTBsmLE+7CKt1j9\nyN91FbjJ3zGaX/Ezdi3ByiFYixslhiRYVgwO1u/De9l/HS75mn38s/3z8+Z99FqClUOwFjdK\nDEmwrJj2s4TFufU/N8UFN7/r1wbmPvAj8PsFNzRYrwTrjEoFI8EKjPhtDf9+Ks6x54RvBv75\nepPdfP3TuDYw94Efgd8vOIK1uFFiSIJlBb8Py9RIsBY3SgxJsKwgWKbGZrDixSJY51QqGAlW\ngGCZGgnW4kaJIQmWFQTL1EiwFjdKDEmwrCBYpsYRwRr/K/z8LtvSKDEkwbKCYJkaCdbiRokh\nCZYVBMvUSLAWN0oMSbCsIFimxoHBKi4jWOdSKhgJVoBgmRoJ1uJGiSEJlhUEy9RIsBY3SgxJ\nsKwgWKZGgrW4UWJIgmUFwTI1EqzFjRJDEiwrCJalsdQgguVXqWAkWAGCZWkkWG/ps21qJFgB\ngmVpJFhv6bNtaiRYAYJlaSRYb+mzbWokWAGCZWkkWG/ps21qJFgBgmVpHBis/UVji+V22aZG\niSEJlhUEy9JIsN7SZ9vUSLACBMvSGAtWpEsE67xKBSPBChAsSyPBekufbVMjwQoQLEsjwXpL\nn21TI8EKECxLI8F6S59tUyPBChAsSyPBekufbVMjwQoQLEsjwXpLn21TI8EKECxLI8F6S59t\nUyPBChAsS+OwYB0uIFhnUioYCVaAYFkaCdZb+mybGglWgGBZGgnWW/psmxoJVoBgWRoJ1lv6\nbJsaCVaAYFkaxwVrbLHcLtvUKDEkwbKCYBkaywEiWH6VCkaCFSBYhkaC9ZY+27ZGghUgWIZG\ngvWWPtu2RoIVIFiGRoL1lj7btkaCFSBYhsZhwTr9nWCdR6lgJFgBgmVoJFhv6bNtayRYAYJl\naIwHq94lgnVupYKRYAUIlqGRYL2lz7atkWAFCJahkWC9pc+2rZFgBQiWoZFgvaXPtq2RYAUI\nlqGRYL2lz7atkWAFCJahkWC9pc+2rZFgBQiWoZFgvaXPtq2RYAUIlqFxbLBGFsvrsm2NEkMS\nLCsIlqFxULDKfyNYZ1EqGAlWgGAZGgnWW/ps2xoJVoBgGRoJ1lv6bNsaCVaAYBkaCdZb+mzb\nGglWgGAZGgnWW/ps2xoJVoBg2Rkr+SFYfpUKRoIVIFh2RoL1lj7bxkaCFSBYdkaC9ZY+28ZG\nghUgWHZGgvWWPtvGRoIVIFh2xkHBav9LL06XbWyUGJJgWUGw7IxtwWp/UkWwzqJUMBKsAMGy\nMxKst/TZNjYSrADBsjOOD9a4YjldtrFRYkiCZYVisBp72v4LrjcjsQMIVsTY/0j28bf3iNlD\nzoZgWSEYrOZXpPkXXO8miB5AsCLlH/BIzg7W2GIpPJAEK0CwohAsIyPBslaabWgfaAar9hXp\nIljNIwjW+GANyE3fkARrzRCsKATLyNgXpAEPQO+Qo4ul8EASrADBikKwjIwEy1pptqF9QLCi\nJAtW7XZrD1bvGSaCNVdptqF9QLCiECwbI8EyV5ptaB+IBqv6FekjWI1DCNboYA35Fh/B6j5u\n3RCsKFVj/zYiWMOMfe86GLL+/iHHFkvhgSRYAYIVZYlgVS8hWDkEy1xptqF9QLCiECwbI8Ey\nV5ptaB+oBqvyFekkWK+Ny1qM7cEatdcU9tm4YA05hUWweo5bN3rByr8azxCs3u9tEawBxugD\nVb16rHKyZ5RxJATLCoIVxTZYpasIVv3qscrJnlHGkRAsKwhWlFTB6rnRmCGXIMED2blEgjVf\nabahfSAbrNYYLMK0YHU9WSJYz73BGnQKi2D1HLduNIPVFYNFmBCsnld3BOt5SLBGK2eIxhhH\nQrCsIFhRCJaJMayudY2LBWtksRQeSIIVIFhRCJaJkWDZK802tA8IVhSCZWIkWPZKsw3tA91g\nlb4i3QSr413rBOu5L1jDzrkTrJ7j1o1osJ4dBqu+SwhWw9gbrPHKOARrrRCsKPW8EKxFjPvV\ntSxywWCNK5bCA0mwAgQrCsGyMB4WR7AMlWYb2gfCwTp9RfoJ1mvjwjZj5JD4JQOHXISzBmvg\nKSyC1XPculEN1rPDYD0vEKwxO01hn40L1nhlGwRrpRCsKATLwtj+Srj1wj5lK2t7qkqwAgQr\nCsGyMBKsBEqzDe0DghVlgWDVbkKwCFYSpdmG9oFysI5fkY6C9Vq/rM0YO6blokFDLsI5gzX0\nnDvB6jlu3cgG69lhsJ4JVqexL1gTlK0QrHVCsKIYB6vjHZRvIlizFj5wyJU9kAQrQLCiECwD\nY2lpBMtMabahfSAdrMNXpKdgte3JWLBmvTLS2GeDgzX4FBbB6jlu3egG6zllsHq+/GMnZwhW\n3dgXrAnKDlb2QBKsAMGKQrAMjAQrhdJsQ/tALlixE7cJ9lnnl3/0ZDLBqhs7zvAZBMvAOByC\nZQXBikKwDIxdwRp+Cotg9Ry3brSD9bqIMsKMYLV8535osFa2z0YEa4qyi3U9kAQrIBysZ4fB\nan+rEcEiWEmUZhvaBwQrCsFa3lhdWG2ZFq+El36jxAgIlhUEKwrBWt5IsJIozTa0D8SD9bqE\nMsKcYDXf4VA3djrfZLBGnHMnWD3HrRvlYD07DFb0LVl1I8Hqeb41VNkNwVohBCsKwVreSLCS\nKM02tA8IVhSCtbyx66yVSbAGWxUeSIIVUA/W6wLKCLOC9dq48JlgdQZrzCksgtVz3LqRDtaz\nw2Ad/lK/AcHqDtYkZQ8Ea30QrCgEa3kjwUqiNNvQPiBYUayDVVz9toJVXxfBslGabWgfEKwo\njScGBGuusbGu6rvXpih7GehVeCAJVkA+WK/zlRHmBSt2g8HBWtd34wcFa9Q5d4LVc9y60Q7W\ns8NgtdygGaw25ZsM1iRlLwRrdRCsKARrcSPBSqM029A+IFhRCNbixuayjpeYBWugWeGBJFgB\n/WC9OgxW5NuKBKs1WONOYRGsnuPWjXiwnlMFq/NLPzYTwaoZO4M1TdkPwVobBCsKwVrcSLDS\nKM02tA8IVhSCtbQxsiqCZaE029A+IFhRCNbSxtiqBjy0XcohDHIrPJAEK6AWrPoXYLHtzxys\n6EwEq2psD9bIc+4Eq+e4daMerGeHwXoeGqyBugFDLsS5gjVNOQSCtTIIVhSCtbSRYCVSmm1o\nHxCsKARraSPBSqQ029A+WEOwXlN8N35ksBo9IliRVe3LbhisQY+mwgNJsALywXp2GKzYKfXh\nwRpcLIV9NihYE5WDIFjrgmBFWSJYbca2Izp8fUMuBcFaCIJlBcGKYh6srldCawxWfE0Ea3ml\n2Yb2wSqC9XeWMgbBWtjYsqbIa+fByoEM8Cs8kAQroB+sZ4fBiuSIYMWuntArgtVz3LohWFEI\n1sJGgpVKabahfUCwoiQJ1ghfz5BLQbAWgmBZQbCiEKyFjQQrldJsQ/tgHcEa+zXfC8Fa2Ni2\nJvtgDXg4FR5IghVYQbCeHQaredn4YF0OH3IgDWN9hHeXffQIGnfRCFbtgPG9mhKsOjON/RAs\nKwhWFAfBatahfchhNIz1GS77g3XZKWjeRT1YvYZ+FghWz+dmPgTLCoIVZXawGs89Gstun3mF\nwTo9wWrMMHIRE76ACNaKIFhR5ger3diLYbAqysbO3QWr11D5e93QfNFYC1bkVeVoZseAYAlD\nsKI0g9WRpaWDFYSLB6vxBKmZm3cDHN2G+tSRYM0t1vwY1D9hBEsHghXlOOTp/gjWM8EaCsGy\nwi5YNvz9+3fQZcvfX/u9LH7/ufBdzqLWhvHv3+rkA+4wYui8i9KB3QckxfILBmzhGVaU8z/D\nGvBcZIlnWK+VA3iGtRA8w7KCYEVZbbBKysb3y6YF67VybXewIgeMh2B1H7duxIIVb8Pf8W/m\n6WFMsIa9lejswcp1ncHaXdlv7DPUk9YI1oBzcz0sEIPap4xg6UCwohCsDkuXgWAZGQlWgGBF\nIVgdli5DPFilU1gEy1hptqF9QLCirDdYR2fjPd9Tg/Vauq47WLEDxkOwuo9bNwQryvqCFWzV\nYFVGz68aYCxPVVM07uK5GazGAeNZIgbVzxnB0oFgRSFY3Z6ogmAZGglWgGBFOXuwhrwBgGBN\nhmCpQrCieAhW786eH6x6bgjWQhAsKwhWlPMGa6e8MgvW5eEuFgvW6/Ga7mBFDxgPweo+bt0Q\nrCirC9bBVQ7Wc3n24oohxtYnaY27OM14DFbzgPEsEoPKJ41g6UCwohyGLN0fwaqanglWOwTL\nCoIVhWD1mp6HB6tyCotg2SrNNrQPCFaUNQfrMtzDgsE6vSu0dkAlWPEDxkOwuo9bNwQrymqD\n9XwKVumP5xnBqj9/6gpW5IDxEKzu49bNKoK1HdaMEawtWCdVS7DCxYOMtVeVjWBV5o4Fa2ax\nlolB+bNGsHQgWFHOHayrq8v+fU2wZkCwNCFYUVwEq29jLxCs458Ea1EIlhUEK8qqg3V5OlO+\nULBey29JbQlWywHjIVjdx60bghUlEqzWMGkF6/kQrP09zQ/WsUeRO6sGK3bAeAhW93HrhmBF\nWVmwyqJosPYHDDMebG3BKn8cDda8Yi0Ug9KnjWDpQLCiEKwBtqHBqp/CIliWSrMN7QOCFWXd\nwbp8XTpYr5d9wWo7YDwEq/u4dUOwopw5WM9XV1fPRsF6DsHa/2WJYD2HYEXvrhyslnnGQrC6\nj1s3BCvKuoJV9USCdThgoLH21ohGsEp3GA/WrGItFYPTg0CwdNAKVksbzIJV8bbcycD7HrXs\ny6ur+mmfOUqCFYNgKUKwohCsAT6C1QrBsoJgRfERrJ59PTlYO3v1/bCzg3V11ROsS4KVSGm2\noX1AsKKsOVhHe8ESwTp8VzNyh6VgdUw0CoLVfdy6WUewhlZjMKsKVt3SCNbxgFHG8o8t1YJV\nNUaCNadYi8XguACCpQPBikKw+o1DgxU5hUWw7JRmG9oHBCvKqoN1Fd40EVgkWBVj5S630VNY\nBMtOabahfUCwoqw6WJXnQ4sEq/KcrXKX2/grQoJlpjTb0D4gWFEIVr+RYLVDsKwgWFHOG6zL\ny6vX5YLVkNSDVf2e3mBnV7DK33eMBmtGsZaLwWEFBEsHghVlzcGqvmtqiWBV39lVudPt4R4I\nViKl2Yb2AcGKcu5gHd6L3rmtJwer8r708A9ejByyHqzL+qPQCFbfVMMhWN3HrRuCFYVg9TsJ\nVjsEywqCFYVg9TsHBit+CotgWSnNNrQPCFaUbeTuRIPVPOdeC1bpFPzwISuNigTr9Bu2WoI1\nvVgLxmA/NcHSgWBFWXGwXmsnwecH6/Ky/DtMq3e7bTnnTrCslGYb2gcEK0osWC13IhisyoWL\nBKv5MNSC1T/XYAhW93HrhmBFIViDRyRYEQiWFSsJ1tLFOmuwSme05wcrdgqrcmn5xwDHDHl6\nr2g0WPu7aA/W5GItGYMwNcHSgWBFWW+wXg/BOlw8O1iXh2DFnmJtw3chCVYypdmG9gHBirLq\nYFUvXiJYJXHtjreVt010TjYUgtV93LohWFG8BKtzVy8TrPLPARKshSBYVhCsKASr1zswWK2n\nsAiWjdJsQ/tAKlhtbThnsIbe8T5xbzAAACAASURBVJmCFT/nXrr8+IPWI4c8vZRsCVa4vCNY\nU4u1aAyKqQmWDgSrzdi8v5TBGnISa0qwXk/ey/0BM4N1eQpW5CnWtvWcO8GyUZptaB8QrDZj\n8/5WEqzqFUsEq6Yu3/W29RQWwbJRmm1oHxCsNmPz/ghWGYLVAcGygmC1GZv3lyhYYR8TrDYI\nVvdx64ZgtRmbTsFgtZ3COp56qv6ihTGfm/2P9FyWg9Us1rb+j0J3TTeMZWOQD02wdCBYbca1\nBqt61RLBisiP97Bt/JOFHdMNg2B1H7duCFab0Uewujb1QsEqXUiwFoJgWUGw2owEq5thwfrb\nfgqLYJkozTa0D9YSrIWLRbD6OJxMJ1gxCJYVBKvVuIJgtZ9z358tr/1mmFHBet0LysFqFOtv\nxzn3icVaOAa7oQmWDgSr1bjOYFWvXCJYLfrnY7CGzzcIgtV93LohWK1GgtUFweqCYFlBsFqN\nZwpW7WeJCVYdgtV93LohWK1G/WB1ncIKJ7EqT+bGButkiPqLu/hfZ7AmFWvpGLy+/l3YSLDs\nIFitxqYydh9WwRrwztEpwapdvUCwOu4gBGvMhEMgWN3HrRuC1WokWF0QrC4IlhUEq9XoI1gd\ne3qpYJ0uXzxYV//rfEVIsJZXmm1oHxCsViPB6oJgdUGwrCBYI4xiweo+5176RQtTg/UcCVb1\n0egL1pRiLR6D17+L/lhXDsGyQjFYjS/x0cHqPXT5YL0bdNTzmGD977KHq6vXGt131fzctK/t\nEKzGpRV2wepd7VjeTbhNJ7sh+zj7jJeXBKtAMFiXjR08Nlj9xy4erN2X8LDZjqvrDVb+7KWT\nq9nB6ljc2wrW2GIRLCsIVpSVBKu7V8fnqpOD1XyyW7/H//Usd0Kxlo8BwdJBM1i1fTIhWD0H\nWwRrWLEuhwbrqu/ZS/8qS0eGD7aNy3uC1csZT+YsZxz+SA41ToBgFSgF63AKKxqsEcWKPtlo\nGgcFa2ivxger741Yu2B13/eoByR8MDxYQ+WrCNb47+gQLCsIVhSCtb+cYOUQLDfoBevyjQWr\nrVgLBut4aCRYLQ6CNc84HoJVQLCiEKz9xQQrh2C5QTRY1S08JVjdB5sEa1Cxhgbrqi9YY84U\nx4PV9Ti9uWCNKxbBsuINBis/MHGw8u9Kjw5W90msXbC2nXc+8tumxZ8EqwWC5QWCFeVswSof\nRbASKQmWDgQrCsF6JlglCJYXVINV2cOTgtV5tE2wBhRraLCu+oI16rRLNFivBOvI2JNYBMsK\nyWDV9/CoYIXjkgYrH3c77BcTVA46LbjBrlc7Zce9j9phbcFqt7yxYI19ikWwrCBYUbZD60Sw\nuiFYS0GwCghWFIJFsCoQLCfIBavYvm8qWNEbLhusw9GNYLVqCNZc41gIVoFssMp7eFqwug6P\nB2vYaa0mx2D1F2tgsK76gjXyLHEkWK8Eq8TIx5NgWaEZrOdIsAbuocNRCYNVDLsd9uuAq8e0\nvibMe9U25OC5modvGxe1eAbr1xKskQ8owbKCYEU5V7BqhxCsJEqCpQPBikKwCFYVguUD3WCV\nNvHEYHUcbhWsvmINDNZVX7BGnnKJBOuVYFUY94gSLCtEg/U8O1jdh5sEa8BTrOHBah9y6FiR\n47eNSwjWAYLlgrcWrNNByYIVRp0UrMqSSxyDNTso1eMJVjsEywUEKwrBIlg1CJYL1IJ12Lxv\nKVjN2y0erP0NmsFqMRGsBYzjIFgFwsE6beKpwWo/3ixYPcUaFqyrvmCNPefeDNYrwaox6jEl\nWFaoBut5drA6j7cJVv9TrMHB2g85tye1W2xrf59/B+sJ1qgHlWBZIRSs6vmcacEqH9MdrOi1\njQsH92pYsJrXR09ilYI1cM5eCFYvBMsDBCsKwSJYdQiWB5SDddzFk4PVegO7YHUWa1iwrvqC\nNf4UVj1YrwSrwZhHlWBZIRus59nB6rqBUbD6nmINDtbzUTnsVFsvzWB1ut5isMY8rATLihUF\na8AXVPWIJME6jDkxWNXvNAQqwYqNYB6s4XdAsJaCYBUQrCgEi2A1IFgOIFhRCBbBakCwHCAW\nrNLWLZ3Anh6sthsYBqurWC3Bql5+1ResCefc95rt6S+db1d7s8ESWLbZhvaBbrCeZwer4wZW\nwep5ijU0WIch4yNM6VUjWJ02iZ27vFFi2WYb2gdvKlj1AxIE6zjkkGBFr2y8JqwFa9K3LuN3\nQ7C6kVi22Yb2AcGKQrA6bRI7d3mjxLLNNrQPtINVjcGUYLXcwjJY7cUaFKyrvmBNOoVVCdYr\nwYoy/JElWFYIB6sRg9HBar9F27+gNfw5WsuMnU+xhgbrOOS0maLUgtWte6PBGr5ugmUFwYpC\nsDp1BGsp43AIVsFbCtaI76dtW64ZG4fGebbxwcrvozNYw7/32QXBGgDBOjviwaq8ZWBSsOI3\nMQ1Wa7GGBOuqL1jTTmGVg/VKsFoY/NgSLCu0glXb0bOD1XoTu2B1PcVqDVbpmlOv2oPVOVIb\n+e2i7+wa8bA1WVewBi+cYFlBsKKHEqxOIcFazDgYglWwpmD1fTl5D1bLNf6CNeIuCNZSEKyC\nNxSsMSdjFgpW8we0JwSruvBIsPpPkg+BYA2AYJ0b9WCVfjnexGBFb2IbrJZiDQnWVV+wJp5z\nLwWrbiBYJ4Y+ugTLCulgPc8OVttNDIPV/hRrYLBOQ8ammNqrSrAaVzQPHcjKgjV06QTLCoJF\nsE43JFh9EKwzoxOsxtuwnscFK37lvGAN79WcYO3u5qozWOU5CJapkWCdGflgXT7PDVbsYuNg\nxcM0IFhXfcGafArrGKyGgWCVGPj4EiwrpILV3NGzg9VysWWwWsM0LFilISNzTO5VOViRa7ov\naGdtwRq4doJlBcGSCNZh6YbBym9KsHohWOeFYLkJVvsbtAiWrZJg6fBmgtV2Xfzyv8OO7v7q\nrYw7J1in14QtwToNQrCMjQTrvOgH63J2sCJXWAcrlqYBwbrqC9b0c+6HYEUMBKvEsEeYYFkh\nHqzn2cGKX2EarJY0DQtW6dJ4sDoG6uYYrMgVPRe0s7pgDVs8wbKCYBGsk4Ng9UOwzkojWBef\nn5Yxz33g6wwIVtcXE8HqY3CwxtwJwVoKglXQCNZms1mmWXMf+DqtwbocEqzOa5pXLRGs6rS1\nYEXa1PXLk1+vri7rp7AqyjDJnFNYIVgxA8EqM+gxJlhWNIL18u26aNbDXPPcB75OPFjPs4MV\nvaotWLWDJwYr3qZBwSpfGA1W+zx9HIIVu6Lz712sL1iDlk+wrIidwwrNyu7mNWvuA1+n9AN1\nZd5IsIrF2wZrd+u/ccO4d59VIFhLQbAKWk66L9CsuQ98nbUHq6tXBMtUSbB0aP8u4f614Zep\n5rkPfB2CRbCMlARLh/ZgPdxlm5zsfpp57gNfpz1Yl/3B6nnDQ+PKBYJVC1A9WPHvd7YPeXV1\nedURrGKUWefci2DFDQSrzJBHmWBZ0RKsp88Xu1Z9uN9la7OZVqy5D3ydlmA9zw5W7ErjYMXq\nNChYlctiwepQ9BKCFb2CYJUgWGcketK9qNX1t/C3b5uLSea5D3wdgkWwjJQES4e2tzV8ezkd\nMu3d8HMf+DoEi2AZKQmWDgPeOOr/Gda70zGD3u/ZvLb+syd/h5287/DW+9MIVvwXT7RydVU/\nhVVTvr7OPIVFsAYy4HEmWFY0gpXdPS5jnvvA12kL1vPsYDWvNg9WJE9DglW9KBKsLkMvRbDi\nVxCsMmsIVnjdFH31NPmNAROp31/nSzqhH34u3uwdgWAdZrEK1pg3c9QgWEuRLFjXdk2I0ri/\npYL1432WffxRvuTXpyz753f+UXbkeOXcB77OyoPV06t8+dbBeiZYw1hPsMZdY8O4+4sc/HJX\nnLTKPlTfzvApBOnT6ZJf4ZK8WMde3RyvnfvA1xkSrLYvJYI1iGHBGnU3BGspCFY4unHJ/ebw\nbHFzXbr4V3bzc7v9eVP0KfAp2z3f+lFO2MfStXMf+Bqtp7DyYF2ejhpw0jh2ffWAgcEa0atI\nsKL/xGI7fcGa+7bRZ4I1lP5HmmANZ2awnjabD+EtDffX5WJ9z/7N//iZnV4Uhtd/pVeBP8Ix\ngbkPfI32YD2PD1Zd9FpndLAum1RvWF927w3qNHoVCVa3oZfWZROsKo2vl+bXz+IsFazdtt58\neKqew/p2u3t6cnsfLinIP3y8y9/hdP055GB32cOH/C0ER9GH/KeND28oePyQHRSlumy2jzvH\n9ePxbhsHn+5v95+7zebuVLDqHRyU9fXc5TfZc705ncD/lP0q/iw9oboJwTq+CvxdfrLlOViN\nOES+4FrHiG7dSH4IVg7BWoqFgnUdAvGtHKz9ZcXzk1NA7vYfbrKncOj+gv0TlNv9tff7bARu\nq3XZ3IeLH+9KpsrB5WDtAlUKVvUOjsr6grLN6S2jT6W3YN3s5yydpfoeXhJ+P/z9U/ZHNFiN\nr8C/7WMMDVbtho1lj+zVrlj1C+rKub16fm5bdsuqB7DOYPUWy22wbjcXD7uNfbspBeuueAq0\nfbgIz0/2vbjfZPd5Cu4vNh/CxZvb/JlStvkcRPkPGb/s2pMf9Dn8yPHh2FOw8pdrL9ebi83d\nS/5kq3gyVDv48IQqz+j25elwQfUOTsr6iiqvKEt/ObzyK70C3H6/ybJTr35mXw8f/t+Ozsdt\nPH///u/du/hV705X/P37N3bT2qXv2kxDxvgb+8sMowItqwY1Hg/Pjy5Kwcr2u3z//GS/6S82\n+zdkvhwODc+e7oujHg/Plj7kEXrZZC/b6q22pds8bEKaHoqb1g8+Bevz4YPGHZSU9SWNCNZ/\n7/PvC378tf/r+8oTLEfPsOoXDng60zpk/LnGgOdH0k81eIZ1duMyJ93vNvufEL4vBWuzqf5k\nS/x9UZvNQ+mvd4ezRS95hD4fX7fdV/JyuM1mn7HipvWDT8F6bL2DkrK+pA+l14z3pZekzWD9\nl338vd3+/pj9V/y19ASrYO4DX4NgJVASLLfGZYJ1fWjTUylYu9eHd/ctPzv8+OU2q73HtPjg\nuhK50ns/K3k5tahy0+rB9YNid1BS1i+4PzwV2+ZP2U7xap7D2j+j+pN9LP5afktDztwHvkbr\n27B2vDv2YnCwegJDsKqUl02wzmFcJlinGJUq9FT84ruLu4faMfcfstL3DKs9qT4N25SJ3F3l\nz/rB8WC1vdmhefHtJvuSJ+vpS1Z+W8P+u4S/Tt8JrD7n+pO9r3rmPvA1CFYCJcFyazQM1vbp\nw/77f+WT7uF7ebdfHus/xeMtWMdvJ1a/R/k9vAGr9E3B/XOuP+E517+nKwJzH/ga04P1umSw\n4luXYI02TkchL1rB2hYv/fId/+V02Zf9E5fGodFgdd9dLVjdB40O1uENY9Vf2/D78E73wzn2\n7dfsn1/FOazi3NU/+1NZR+Y+8DVmBavy9yFvIhgXrAG9Et+5BOvcRsNzWAcersvnlJrfJSz3\n5HSKKf++4/Um/iteWs5hPXYeFLuD0tGd6ytT/lnC8Crw4/7HB4tTWe9rp7AI1lDjZAjWGzIu\nE6zPh++9ld84enrrZfm5zbEf32LBOn4T7z5/x8Jd9a0HR6LBqh8cD1b1DkpHd66vwr+fbrL3\n4Qdz9qevvr/f5err7/JFJ+Y+8DUIVgIlwXJrXCZYT4dvqZW/9XcsyGP5GVa2fyL0FP0u4fEN\nXdf5N+Yej+9Hv6+cR4oGq35wPFjVOygpO5f3cNt1dTdzH/gak4MVP4VFsEYZCda5jQv98HN4\nl/nDRflbfy/7n/K7z4p3aWW7QrzkGcvfE//yJf9O4dO23pP8LfM70dP+543vNpsvu9s83W1q\nbxyN/Vk7eH9/3XdwUjaWdPiWQeOU/0jmPvA1hgUrspsiveovzKhgDemV+M4trXpUr8SX7ci4\n1G9r2O/uz+WnTfeH3X53PKIISfjW4f1F8fbPWk8OP4C4z8nxBw+rT4eiwaodfLi/7js4KusL\nejm896J4b4aff/mZYCVQEiy3xsV+vUz+axOuH6rf+nu62z3lyj7snxx92P+Ac35h/rsaHiqv\n3I4f3N+W/53lh/xNW4ff7LCtHVr/s3rw/v567uBwZX09nzcXL8VPF718yyb+i4SBuQ98jeYv\nKzgxOli9jSFYNU7LJlhnMS4WLHEawSrOcd0WLy6fsuwlcpOBzH3ga3QFa3vZfhIrdgqLYI02\nEqwzGwlWoBGs4vnYl/A9xS+bz40bDGbuA19jRrCqFxCsKUaCdWYjwQrEg/UYvjn5Uj/jNYa5\nD3yNpYIVDl0yWIN6pb5zCdaZjQQrEA9W481jE5j7wNcgWAmUBMutkWAFIuew8vNW2Wb/a1Gn\nm+c+8DUIVgIlwXJrJFiBRpHuim8NfihOYj1M/FfqC+Y+8DUmBit+zp1gjTUSrDMbCVagEazH\nTfZY/Fasx+3jRcuPCA1i7gNfY3qwqscSrElGgnVmI8EKNF/z3e1/vqh4l+sM89wHvkrX+0bH\nBGt/5CLBGtMr9Z1LsM5sJFiByEmq++J14JeLTTbj+ZXzYPVlhmDVIFhnNhKswIyz6j3MfeCr\ndL0i3CmP1ahtp5ZTWARrtPG4boJ1FiPBCjRPutf/qdWpzH3gq0wPVvVQgjXRSLDOayRYgcj7\nsGb8OE6ZuQ98laHBqu2ntidYywVrYK/kd+5h3eN6Jb9sN0aCFWh54+gCzH3gqxCsFEqC5dZI\nsAKR92F9W8Y894GvQrBSKAmWWyPBCjSfT33YfI7/RvmRzH3gq0wLVus59+nBqn+/jGBNNU5F\nIS8Ey4rIS8K2f2RsJHMf+CqTg1U9kmBNNRKs8xqXCdb/2870nZ6UtxWs02FLBWtor+R3LsE6\nr5FgBdb2PqyhweopDcGqQ7DOayRYAZFgXV5ddeyTtmC1n8IiWKON+3UTrPMYCVZgJcGKv3O0\n/RQWwRptJFhnNRKsAMEaOyTBWso4EYW8ECwrRE66LxOscl2WCdbgXunvXIJ1ViPBCqw5WF2n\nsAjWWCPBOqsxdbCy2y+HHyp++nLb/num2hLxpfTfJeko0sN15ubfJZwarJqFYE03EqyzGlMH\n6/DvQG/D78ZrNbZclW1O/12UTuP1ZsZvbpj7wFcgWEmUBMutMX2wrg9Pq7Lr8cGq/Fs2S9Jp\nfNh8mG6e+8BXGB6sjl81V61LZ2sGButqcK/0d25Y98he6S/bizF9sL5tHvYV+KYSrO2c35E8\n94GvQLCSKAmWW2P6YL3sXxPe7T4q/rHSD9lmc/ElXLm9y8LHuw+/7D4sfmPC6Yhw/vtwFjx+\ny2n0BMvJSffLy6uujRIPVuc5d4I12lgsnGCdybhQsP6/OLFgbfevCbProgN3+2/DfS6uvCg+\n/pJ/+OHwYemISrBabjmNziLde/lnvvqDFTmJ1XkKi2CNNhKscxrPEKxvxb/4d7/5VgRrU/ze\nqc/Fi67NJnvIQ3Rx+vC6fsS29N/oLafRFaz7bHoICdZw41QI1hsyniFYL8Up7A+bl/IrreLD\nTXF66yV07Phh9Yjjh223nEb3+7Cup2q3Cwer8xTWwGDVCjU7WKN6tYKdS7DOaUx/Dit/l0D+\nwfUhPC/fbm8vSjnaP/E6ftg84tCl6C2n0RWs61lv+5r7wJeZEqyeU1gEa6yRYJ3TeI5g5a8J\n81eEoS8fTu8lbwlW44j9lfFbTkPjZwknBqsmIVizjATrnMZzBCt/TZi/ItyfdL+4+/Lw0hGs\n5hHhvy23nAbBGjskwVrMOA2FvKwjWLvXhC/FaaFTmR47gtU8ovzfxi2n8XaD1VksgtWEYJ3T\neJZgfdvcFt/hO36X8D7rDFb5iKfSf6O3nEbkhi93xfccsw9zfpLQX7AafZodrKur4b1awc4l\nWOc0niVYu5dxxT9Tmv/l8+HU9kNbsMpHXGzydzGE/7bcchrNG95vDk/kZn2T8NzB6jvnPjlY\npyISrJnGaSjkZSXB2r0mvD7+5XO2yT48PG5uW0+6l454uMhTFf7bcstpNG74tNl8CP/28/21\nl7c19LwNKygP/Wn7IV2CNdeYL5xgncmYOlheaQTr7vhbJfK++njjKMFKpCRYbo0EK9AIVrZ5\nOX785ORHc0YFq+WndJt5mhuszn/IZ5RxImcI1therWHZPowEKxB542jbX0Yy94EvMSFY/aew\nCNZYI8E6o5FgBVYcrLqDYM00EqwzGglWoFGkD5vTuxnu8/P6U5n7wJcgWImUBMutcZlg6dMI\n1v0mO/5e5IvNjLdizX3gS9gEq6tYBCsCwTqjkWdYgeZrvttNVvx7GU9fMsm3NcSDFYvTvGD1\nvDdsjHEiBOsNGQlWIHKS6vb46xpmvCA8c7AGnHMnWGONBOuMRoIViJ1Vf7y7zt/mfvc4yzz3\ngT+xC0v3RokGq+GIeacM+WaD9UywzmckWAGFH34eFqzKO0cJloWRYJ3PSLACBGv0kARrOeMU\nFPJCsKxQ+G0N44M16BTWvGD1nVcbY5wIwXpDRoIVUPhtDZOC1VBEvVOGJFjLGaegkBeCZYXC\nb2sgWKmUBMutMXmwSv+4Q5ut9Otljn+3RuG3NVgFq6NYBCsGwTqfkWDt76N+gcPf1jAyWJF9\n1VKmGcHqnWmMcSJnCdayxiko5GUVwerd4vVDzhIshz/83PtkJhKsumH5YI17grWKnUuwzmck\nWPv76ByCYEUgWMsZp6CQl7UFq/Kbjb9c789zl14S3mWbu/3H97urr8M7DB4/ZJvNxZf9TXfH\nXMz6p04LT/0Cf7+tof/V1/Z4YPEnwbIyEqyzGRcK1v8TZ0ywrovzWtm2HKzistvi47tw3uvu\n9OHmc3HsRfHx3GIJ/LYGgpVMSbDcGs8QrNI591KwdoF42L5c50U6BuvbJnvcPhb/kNfD5vph\n99TqOk9H8e97bT/v47a7Wf5vqk4vShihcYm739YwP1htYZoerNHn3NexcwnW2YxugnVbPIt5\nyctzDNZt/i945e/g3IZ/KTq//rZkKv7zUFw89zSXwG9rmBKshqHN3G2Ms/MTrIWME1DIi9tg\nzT+HVbr8+NfK1eU3Q7x8u729WOZfUD3cZ+QyZ7+tgWAlUxIst0bJYH2IPkebhcAPP48O1nP9\n4NYwtV5BsOKM7dVKlu3AqBOs063uNhd3Xx5eCFaLsuOJFMFajVFiyPUFKz8z9VA+h5VVzmHd\nn67+VlM8pgvWw52H92EtEax2dacxDsE6p1FiyLUF6yL/puBDtv8u4WP9u4T3p+8S7j7cFevl\nc/h36Xcf3meJgvX0OQvvtpjI3Af+CMFKplQwSgy5imCVzkZ9Ce+tKr0P63pbfglYfKPuQ/l9\nWPmboz4fBA/mwXr5lo91O+c3Ys194A/kUfEWrKv+mUYZp6Gwz1h2amXnppwarO23i012eCv7\nl+LjbeWc1efqO90v7l72l2YfHh7Ds63t4SaziN7+Pj+7n31+iV03mLkP/IHhwRr//lCCpWeU\nGHIFwXJKM1iPd1nn75QYytwH/sDsYLWfcydYgkaJIQmWFbUuvXzOf+Ln+tsCP3g994E/sESw\nutydxigE65xGiSEJlhWVLuWvPjcXnw8/iD2PuQ/8AYKVTqlglBiSYFlRfbPFJrt7Onw81zz3\ngT9gGazW6wiWW6PEkATLimqw7kofzzXPfeAPzA1WxyksgiVolBjSa7D0aTzDejx8PNc894E/\nsECwuuVdxigE65xGiSEJlhXrP4dFsNZllBiSYFnh/ruERVKcBevqqn+mUcZpKOwzlp1aOXff\nOsf9+7DGBGvsP0hPsASNEkMSLCvcv9N9brA6z7kTLD2jxJAEywr3P0s44BRWX7B67J3GGEWw\nxv4uO3auX6WCkWAF3P+2BoKVUKlglBiSYFnh/vdh2Qar7WqC5dYoMSTBssL9bxydGazuU1gE\nS88oMSTBsuINBKtX32WMcnV1RbDOZZQYkmBZQbAIlpZRYkiCZYX3YA15V0PqYF1eXb0SrHMZ\nJYYkWFYQLIKlZZQYkmBZsa5gNfrTd86dYMkZJYYkWFasP1gD/F3G2G0I1hmNEkMSLCsIFsHS\nMkoMSbCseOvBajmCYLk1SgxJsKxYd7B6T2ERLDmjxJAEy4rVB2vQHXQYYzchWGc0SgxJsKwg\nWARLyygxJMGywnmwQk58Bevy8uqVYJ3NKDEkwbKCYBEsLaPEkATLipUFq9qfAefcCZaaUWJI\ngmXF2oM18B46jJFbEKwzGiWGJFhWECyCpWWUGJJgWfHmgxU/iGC5NUoMSbCsWHOwhpzCIlhq\nRokhCZYVKw/W4LtoN0ZuQLDOaJQYkmBZQbAIlpZRYkiCZYXvYA3rVdpg7Y5/LRjgHmacisI+\nY9mplWYb2gcrDtawU1gES8woMSTBsmJtwSr1Z1ivpgTrmWCdzygxJMGygmARLC2jxJAEywqC\nFT2OYLk1SgxJsKwgWARLyygxJMGyYr3BGnjOnWCJGSWGJFhWrDpYY+6k3Rg5nGCdzygxJMGy\ngmARLC2jxJAEywrXwdqnxFWwDr+zmWCdySgxJMGyYrXBGnwKi2BpGSWGJFhWrDlY4+6l1Rg5\nmmCdzygxJMGyYnXBOtyIYK3UKDEkwbKCYEUPJVhujRJDEiwrCBbB0jJKDEmwrFhrsIafcydY\nWkaJIQmWFSsO1ti7aTU2DyZY5zNKDEmwrCBYBEvLKDEkwbLCc7AOIfEUrON77wnWmYwSQxIs\nK1YarDGnsAiWlFFiSIJlxXqDNfhuCJaUUWJIgmXF+oJV3IxgrdYoMSTBsoJgPceKRbDcGiWG\nJFhWEKxngiVllBiSYFkhEKz+NjSCNeqc+4Rgjf5nVNm5npUKRoIVWG2wBt/LM8GSMkoMSbCs\nIFjPBEvKKDEkwbLCcbAGn8JKGKzhM9Vh5/pVKhgJVoBgPRMsKaPEkATLirUGa+idVO6pzThl\npjrsXL9KBSPBChCsZ4IlZZQYkmBZscJgjftBwspdtRknzFSHnetXqWAkWAGCVb6rNuOEmeqw\nc/0qFYwEK0CwynfVZpwwtjQShgAAHMBJREFUUx12rl+lgpFgBVYarKH3cbpFlXezZ+qZcQkU\n9hnLTq0029A+sAvWXN69exc++Pv378RbjrlFnYVnAoAF8PsM6/g8afQzrOexT7CaT7HexRWn\n525jn2DxVMOxUsHIM6zAKoM1m/5gjYad61epYCRYAYIV5V28TATr/EaJIQmWFQQrCsFya5QY\nkmBZQbCiECy3RokhCZYVBCsKwXJrlBiSYFlBsKIQLLdGiSEJlhUEK26Mp4lgnd8oMSTBssJt\nsEpveXITrBm9Yuc6VioYCVaAYMWNBMurUWJIgmUFwYobCZZXo8SQBMsK/8Ea8HPGFl9wsTgR\nLAdGiSEJlhUEq8VIsJwaJYYkWFYQrBYjwXJqlBiSYFlBsFqMBMupUWJIgmUFwWoxEiynRokh\nCZYVBKvNGKkTwXJglBiSYFnhNVhj3tWQKlhzesXOdaxUMBKsAMFqMxIsn0aJIQmWFQSrzUiw\nfBolhiRYVhCsNiPB8mmUGJJgWUGwWo2NPhEsD0aJIQmWFQSr1UiwXBolhiRYVhCsViPBcmmU\nGJJgWUGwWo0Ey6VRYkiCZQXBajUSLJdGiSEJlhVOg1Vqw9mCVQ/UrF6xcx0rFYwEK0Cw2o0E\ny6NRYkiCZQXBajcSLI9GiSEJlhUEq91IsDwaJYYkWFYQrA5jNVEEy4VRYkiCZQXB6jASLIdG\niSEJlhUEq8NIsBwaJYYkWFa4D9aAXhGst2SUGJJgWUGwOowEy6FRYkiCZYXPYI17RWj3BVdu\n1LxesXMdKxWMBCtAsLqMBMufUWJIgmUFweoyEix/RokhCZYVBKvLSLD8GSWGJFhWEKwuI8Hy\nZ5QYkmBZQbA6jaVBCJYPo8SQBMsKgtVpJFjujBJDEiwrCFankWC5M0oMSbCsIFidRoLlzigx\nJMGywmWwym3wEqyZvWLnOlYqGAlWgGB1G4+jECwnRokhCZYVBKvbSLC8GSWGJFhWEKxuI8Hy\nZpQYkmBZQbC6jQTLm1FiSIJlBcHqMR5mIVhOjBJDEiwrCFaPkWA5M0oMSbCsIFg9RoLlzCgx\nJMGygmD1GAmWM6PEkATLCo/BqrTBSbDm9oqd61ipYCRYAYLVZwzTECwvRokhCZYV3oM1pFcE\n6y0ZJYYkWFYQrD4jwfJllBiSYFlBsPqMBMuXUWJIgmUFweozEixfRokhCZYVBKvXWIxDsLwY\nJYYkWFYQrF4jwXJllBiSYFlBsHqNBMuVUWJIgmWFw2CNfhtWgmDN7hU717FSwUiwAgSr10iw\nXBklhiRYVhCsfuNlwZLGZVDYZyw7tdJsQ/uAYPUbCZYno8SQBMsKgtVvJFiejBJDEiwrCFa/\nkWB5MkoMSbCsIFgDjATLkVFiSIJlBcEaYCRYjowSQxIsKwjWACPBcmSUGJJgWeEvWNU2uAnW\nssZFUNhnLDu10mxD+4BgDTASLEdGiSEJlhUEa4iRYPkxSgxJsKwgWEOMBMuPUWJIgmUFwRpi\nJFh+jBJDEiwrCNYg4+xesXMdKxWMBCvgPFiDeiXxBcfO9atUMBKsgLtgTXiCJfEFx871q1Qw\nEqwAwZI1SgzJslMrzTa0DwiWrFFiSJadWmm2oX1AsGSNEkOy7NRKsw3tA4Ila5QYkmWnVppt\naB94C1btHU8EK6lSwSgxJMGygmDJGiWGZNmplWYb2gcES9YoMSTLTq0029A+IFiyRokhWXZq\npdmG9oGzYNV/aI9gJVUqGCWGJFhWECxZo8SQLDu10mxD+4BgyRolhmTZqZVmG9oHBEvWKDEk\ny06tNNvQPiBYskaJIVl2aqXZhvaBr2A1flEewUqqVDBKDEmwrCBYskaJIVl2aqXZhvYBwZI1\nSgzJslMrzTa0DwiWrFFiSJadWmm2oX1AsGSNEkOy7NRKsw3tA1fBav7jNAQrqVLBKDEkwbKC\nYMkaJYZk2amVZhvaBwRL1igxJMtOrTTb0D7wHaxhvZL4gmPn+lUqGAlWwFOwpj7BkviCY+f6\nVSoYCVaAYMkaJYZk2amVZhvaBwRL1igxJMtOrTTb0D4gWLJGiSFZdmql2Yb2AcGSNUoMybJT\nK802tA8cBavZK4KVWKlglBiSYFlBsGSNEkOy7NRKsw3tA4Ila5QYkmWnVpptaB8QLFmjxJAs\nO7XSbEP7gGDJGiWGZNmplWYb2gd+ghXpFcFKrFQwSgxJsKwgWLJGiSFZdmql2Yb2AcGSNUoM\nybJTK802tA8IlqxRYkiWnVpptqF94CZYsV4RrMRKBaPEkATLCoIla5QYkmWnVpptaB8QLFmj\nxJAsO7XSbEP7gGDJGiWGZNmplWYb2gcES9YoMSTLTq0029A+8BKsaK8IVmKlglFiSIJlBcGS\nNUoMybJTK802tA9cB2tgryS+4Ni5fpUKRoIVIFiyRokhWXZqpdmG9gHBkjVKDMmyUyvNNrQP\nnARr1iksiS84dq5fpYKRYAUIlqxRYkiWnVpptqF9QLBkjRJDsuzUSrMN7QOCJWuUGJJlp1aa\nbWgf+AhWvFcEK7VSwSgxJMGygmDJGiWGZNmplWYb2gcES9YoMSTLTq0029A+IFiyRokhWXZq\npdmG9gHBkjVKDMmyUyvNNrQPXASrpVcEK7VSwSgxJMGygmDJGiWGZNmplWYb2gcES9YoMSTL\nTq0029A+IFiyRokhWXZqpdmG9gHBkjVKDMmyUyvNNrQPPASrrVcEK7VSwSgxJMGygmDJGiWG\nZNmplWYb2gcjgvXjfZZ9/FG+5NenLPvn9+nvP7PSlcMfeILlRalglBiSYFkxPFi7OOV8Ol3y\nK1xyLNbvjGAlNEoMybJTK5eogmMGB+tXdvNz9xzq5tSnXcJ2z7d+nBL2flqwWntFsFIrFYwS\nQxIsKwYH63v2b/7Hz+z0ojD06VipTzcLB2toryS+4Ni5fpUKRoIVGBysT9mv4s/Sa8KbEKyb\n8Lcf2U+CldIoMSTLTq1cIAqeGRysm32MDn3a5k+6ipeE34u//Jd93RKslEaJIVl2auUiWfDL\n4GAdYlSO0vfdi8B9r/7cfCxd9387Bo/w7t27+BV///4dLAGAN8CcYP33Pv8m4cfipeLH/GT8\npGdY88+5S/wfkqcafpUKRp5hBWYE67/s4y5Svz9m/223X4tT8gQrpVFiSJadWrlUGZwy4xzW\n++xP/sefrHgxeOB4g6EPfHuWCFZqpYJRYkiCZcXY7xL+On2XsPyci2ClN0oMybJTKxdLg09G\nvA+reAPW4ZuC2+Nzrj+n51yTXhISLD9KBaPEkATLisHB+n14p/uvwyVfs39+Feewvh4uIVgp\njRJDsuzUyoXC4JVpP0sYyvQxXHLz53AIwUpplBiSZadWLlUGp4z4bQ3/frrJ3ocfzNmX6fv7\nXa6+nn64kGClNEoMybJTK5eogmPO//uwCJYfpYJRYkiCZQXBkjVKDMmyUyvNNrQPzh+s9i4R\nrNRKBaPEkATLCoIla5QYkmWnVpptaB8QLFmjxJAsO7XSbEP7gGDJGiWGZNmplWYb2gcES9Yo\nMSTLTq0029A+IFiyRokhWXZqpdmG9gHBkjVKDMmyUyvNNrQPCJasUWJIlp1aabahfeA4WIN7\nJfEFx871q1QwEqwAwZI1SgzJslMrzTa0DwiWrFFiSJadWmm2oX1AsGSNEkOy7NRKsw3tA4Il\na5QYkmWnVpptaB8QLFmjxJAsO7XSbEP7wEGw2spEsJIrFYwSQxIsKwiWrFFiSJadWmm2oX1A\nsGSNEkOy7NRKsw3tA4Ila5QYkmWnVpptaB8QLFmjxJAsO7XSbEP7gGDJGiWGZNmplWYb2gcE\nS9YoMSTLTq0029A+IFiyRokhWXZqpdmG9gHBkjVKDMmyUyvNNrQPCJasUWJIlp1aabahfUCw\nZI0SQ7Ls1EqzDe0DgiVrlBiSZadWmm1oHxAsWaPEkCw7tdJsQ/uAYMkaJYZk2amVZhvaBx6C\n1ZImgpVcqWCUGJJgWUGwZI0SQ7Ls1EqzDe0Dv8Ea3iuJLzh2rl+lgpFgBQiWrFFiSJadWmm2\noX1AsGSNEkOy7NRKsw3tA4Ila5QYkmWnVpptaB8QLFmjxJAsO7XSbEP7gGDJGiWGZNmplWYb\n2gcES9YoMSTLTq0029A+IFiyRokhWXZqpdmG9gHBkjVKDMmyUyvNNrQPCJasUWJIlp1aabah\nfUCwZI0SQ7Ls1EqzDe0DgiVrlBiSZadWmm1oH7gIVjROBCu9UsEoMSTBsoJgyRolhmTZqZVm\nG9oHBEvWKDEky06tNNvQPiBYskaJIVl2aqXZhvYBwZI1SgzJslMrzTa0DwiWrFFiSJadWmm2\noX1AsGSNEkOy7NRKsw3tA4Ila5QYkmWnVpptaB8QLFmjxJAsO7XSbEP7gGDJGiWGZNmplWYb\n2gcES9YoMSTLTq0029A+cBusEb2S+IJj5/pVKhgJVoBgyRolhmTZqZVmG9oHBEvWKDEky06t\nNNvQPvARrEieCNYZlApGiSEJlhUES9YoMSTLTq0029A+IFiyRokhWXZqpdmG9gHBkjVKDMmy\nUyvNNrQPCJasUWJIlp1aabahfUCwZI0SQ7Ls1EqzDe0DgiVrlBiSZadWmm1oHxAsWaPEkCw7\ntdJsQ/uAYMkaJYZk2amVZhvaBwRL1igxJMtOrTTb0D4gWLJGiSFZdmql2Yb2AcGSNUoMybJT\nK802tA8IlqxRYkiWnVpptqF9QLBkjRJDsuzUSrMN7QOCJWuUGJJlp1aabWgfOAlWs08E6wxK\nBaPEkATLCoIla5QYkmWnVpptaB8QLFmjxJAsO7XSbEP7gGDJGiWGZNmplWYb2gdegzWmVxJf\ncOxcv0oFI8EKECxZo8SQLDu10mxD+4BgyRolhmTZqZVmG9oHBEvWKDEky06tNNvQPiBYskaJ\nIVl2aqXZhvYBwZI1SgzJslMrzTa0DwiWrFFiSJadWmm2oX1AsGSNEkOy7NRKsw3tA4Ila5QY\nkmWnVpptaB8QLFmjxJAsO7XSbEP7wEuw6oUiWOdQKhglhiRYVhAsWaPEkCw7tdJsQ/uAYMka\nJYZk2amVZhvaBwRL1igxJMtOrTTb0D4gWLJGiSFZdmql2Yb2AcGSNUoMybJTK802tA8IlqxR\nYkiWnVpptqF9QLBkjRJDsuzUSrMN7QOCJWuUGJJlp1aabWgfECxZo8SQLDu10mxD+4BgyRol\nhmTZqZVmG9oHBEvWKDEky06tNNvQPnAarFG9kviCY+f6VSoYCVaAYMkaJYZk2amVZhvaB26C\nVW0UwTqLUsEoMSTBsoJgyRolhmTZqZVmG9oHBEvWKDEky06tNNvQPiBYskaJIVl2aqXZhvYB\nwZI1SgzJslMrzTa0DwiWrFFiSJadWmm2oX1AsGSNEkOy7NRKsw3tA4Ila5QYkmWnVpptaB8Q\nLFmjxJAsO7XSbEP7gGDJGiWGZNmplWYb2gcES9YoMSTLTq0029A+IFiyRokhWXZqpdmG9gHB\nkjVKDMmyUyvNNrQPCJasUWJIlp1aabahfeAnWJVIEayzKBWMEkMSLCsIlqxRYkiWnVpptqF9\nQLBkjRJDsuzUSrMN7QOCJWuUGJJlp1aabWgfECxZo8SQLDu10mxD+4BgyRolhmTZqZVmG9oH\nPoM1rlcSX3DsXL9KBSPBChAsWaPEkCw7tdJsQ/uAYMkaJYZk2amVZhvaBwRL1igxJMtOrTTb\n0D4gWLJGiSFZdmql2Yb2AcGSNUoMybJTK802tA8IlqxRYkiWnVpptqF9QLBkjRJDsuzUSrMN\n7QNHwSplimCdR6lglBiSYFlBsGSNEkOy7NRKsw3tA4Ila5QYkmWnVpptaB8QLFmjxJAsO7XS\nbEP7gGDJGiWGZNmplWYb2gcES9YoMSTLTq0029A+IFiyRokhWXZqpdmG9gHBkjVKDMmyUyvN\nNrQPCJasUWJIlp1aabahfUCwZI0SQ7Ls1EqzDe0DgiVrlBiSZadWmm1oH9gFazx///5tfAQA\ncIRnWLJGiSFZdmql2Yb2AcGSNUoMybJTK802tA88BevUKYJ1HqWCUWJIgmWFy2CN7JXEFxw7\n169SwUiwAgRL1igxJMtOrTTb0D4gWLJGiSFZdmql2Yb2AcGSNUoMybJTK802tA8IlqxRYkiW\nnVpptqF9QLBkjRJDsuzUSrMN7QOCJWuUGJJlp1aabWgfECxZo8SQLDu10mxD+4BgyRolhmTZ\nqZVmG9oHBEvWKDEky06tNNvQPiBYskaJIVl2aqXZhvYBwZI1SgzJslMrzTa0DwiWrFFiSJad\nWmm2oX1AsGSNEkOy7NRKsw3tA1fBOpSKYJ1JqWCUGJJgWUGwZI0SQ7Ls1EqzDe0DgiVrlBiS\nZadWmm1oHxAsWaPEkCw7tdJsQ/uAYMkaJYZk2amVZhvaBwRL1igxJMtOrTTb0D4gWLJGiSFZ\ndmql2Yb2AcGSNUoMybJTK802tA88BmtsryS+4Ni5fpUKRoIVIFiyRokhWXZqpdmG9gHBkjVK\nDMmyUyvNNrQPCJasUWJIlp1aabahfUCwZI0SQ7Ls1EqzDe0DgiVrlBiSZadWmm1oH/gKVmgV\nwTqXUsEoMSTBsoJgyRolhmTZqZVmG9oHBEvWKDEky06tNNvQPiBYskaJIVl2aqXZhvYBwZI1\nSgzJslMrzTa0DwiWrFFiSJadWmm2oX1AsGSNEkOy7NRKsw3tA4Ila5QYkmWnVpptaB8QLFmj\nxJAsO7XSbEP7gGDJGiWGZNmplWYb2gcES9YoMSTLTq0029A+IFiyRokhWXZqpdmG9gHBkjVK\nDMmyUyvNNrQPCJasUWJIlp1aabahfeAsWEWsCNa5lApGiSEJlhUES9YoMSTLTq0029A+cBis\n0b2S+IJj5/pVKhgJVoBgyRolhmTZqZVmG9oHBEvWKDEky06tNNvQPiBYskaJIVl2aqXZhvYB\nwZI1SgzJslMrzTa0DwiWrFFiSJadWmm2oX1AsGSNEkOy7NRKsw3tA4Ila5QYkmWnVpptaB8Q\nLFmjxJAsO7XSbEP7gGDJGiWGZNmplWYb2gcES9YoMSTLTq0029A+IFiyRokhWXZqpdmG9oG3\nYD0TrDMqFYwSQxIsKwiWrFFiSJadWmm2oX1AsGSNEkOy7NRKsw3tA4Ila5QYkmWnVpptaB8Q\nLFmjxJAsO7XSbEP7gGDJGiWGZNmplWYb2gcES9YoMSTLTq0029A+IFiyRokhWXZqpdmG9gHB\nkjVKDMmyUyvNNrQPCJasUWJIlp1aabahfeAyWCM+jUOUE1AwSgzJslMrzTa0DwiWrFFiSJad\nWmm2oX1AsGSNEkOy7NRKsw3tA4Ila5QYkmWnVpptaB+4C9b4f6he4wuOnetXqWAkWAGCJWuU\nGJJlp1aabWgfECxZo8SQLDu10mxD+4BgyRolhmTZqZVmG9oHBEvWKDEky06tNNvQPiBYskaJ\nIVl2aqXZhvYBwZI1SgzJslMrzTa0DwiWrFFiSJadWmm2oX3gL1jPo3sl8QXHzvWrVDASrIDD\nYI1H4QuOZftVKhgJVoBgyRolhmTZqZVmG9oHBEvWKDEky06tNNvQPiBYskaJIVl2aqXZhvYB\nwZI1SgzJslMrzTa0DwiWrFFiSJadWmm2oX1AsGSNEkOy7NRKsw3tA4Ila5QYkmWnVpptaB8Q\nLFmjxJAsO7XSbEP7gGDJGiWGZNmplWYb2gcES9YoMSTLTq0029A+IFiyRokhWXZqpdmG9gHB\nkjVKDMmyUyvNNrQPCJasUWJIlp1aabahfUCwZI0SQ7Ls1EqzDe0DgiVrlBiSZadWmm1oHxAs\nWaPEkCw7tdJsQ/uAYMkaJYZk2amVZhvaBwRL1igxJMtOrTTb0D4gWLJGiSFZdmql2Yb2AcGS\nNUoMybJTK802tA8IlqxRYkiWnVpptqF9QLBkjRJDsuzUSrMN7QOCJWuUGJJlp1aabWgfECxZ\no8SQLDu10mxD+4BgyRolhmTZqZVmG9oHBEvWKDEky06tNNvQPiBYskaJIVl2aqXZhvYBwZI1\nSgzJslMrzTa0DwiWrFFiSJadWmm2oX1AsGSNEkOy7NRKsw3tA4Ila5QYkmWnVpptaB8QLFmj\nxJAsO7XSbEP7gGDJGiWGZNmplWYb2gcES9YoMSTLTq0029A+IFiyRokhWXZqpdmG9gHBkjVK\nDMmyUyvNNrQPCJasUWJIlp1aabahfUCwZI0SQ7Ls1EqzDe0DgiVrlBiSZadWmm1oHxAsWaPE\nkCw7tdJsQ/uAYMkaJYZk2amVZhvaBwRL1igxJMtOrTTb0D4gWLJGiSFZdmql2Yb2AcGSNUoM\nybJTK802tA8IlqxRYkiWnVpptqF9QLBkjRJDsuzUSrMN7QOCJWuUGJJlp1aabWgf2AWrjf9L\nfo8TYMiFUJiRIYUgWFEYciEUZmRIIQhWFIZcCIUZGVIIghWFIRdCYUaGFCJ9sAAAJkKwAEAG\nggUAMhAsAJCBYAGADAQLAGRIHKwf77Ps44+09zmOr9n+A7ej/viYZe+/7z92OuT399nN1z/h\nY68zFvzcf7q9DvknCxR/8TpkStIG61N49D8lvdNR/Lv/2vA76scw2Mf8Y69Dhhlvfucfe52x\n4Pf+0+12yJ+lYLkdMiVJg/Uru/m5+xzcZL9T3usY/jn8z8ztqF+zj7uR/rvJvvod8kc+459/\niq3ldcbA+/Dp9jvk1+zfw4d+h0xJ0mB9D4/+z8zp09ofN9k/+2C5HfXmGFS/Q77PileDxUPp\ndcaCTzfh0+13yPenPPkdMiVJg/Up+1X86fVZbfb+5/b4GsH3qMWczofMm+p6xh/Zz8OLLadD\n/ikew4DbIZOSNFj7Zwfb0mfBFbtn3IdgeR/1d34Sy/WQvz8WTwUcz/jf7mV1+HS7HfJn9unH\n++x98ZzK7ZBJSRqswwntw58e2c/mfdR/sv98D5ll2ffw5+Hv55wmxp+bj4ex3A75NTt9i8Xt\nkEkhWDU0gvUzP+fuechfHz+FYvmd8WN+esh5sN7n/1/aP1l1O2RSCFYNiWCFXjkf8o/vbRa+\n/+Y8WHt+Z+/9D5kGzmHVUDiH9T30yveQ+zPGbmfMjjge8oDEkEk4x3cJf3n+Pkf1u4QuR/3n\n8I1tz0PmlL6T6W/GcrDcDnlAYsgkJH4fVrHTfmTfU97rOI7vw/I66u+bm//2H3od8ia8D+tX\n/kLG64x7Du/Dcjrk/pH8L/vH8ZBJSRqs34f36v5Kea/j2AfL7ah/bm6ObyX0OuT37OOf/Lx7\nvsO8zrgnfLrdDvk1+/SnOOn+n+Mhk8LPEtbw/rOE/5Reybgdcv/zjsWZNq8zBrz/LKHOI5mI\nxL+t4d9PN/u3wXnl+D0Yp6OWT724HTL8XoGf4WOvMxYcPt1uh8wfyU/7cwBuh0wIvw8LAGQg\nWAAgA8ECABkIFgDIQLAAQAaCBQAyECwAkIFgAYAMBAsAZCBYACADwYISm9LXw91mc3++SQBi\nECwoUQrWNb0CfxAsKHEKFr0CjxAsKHEM1vUmezzrJAAxCBaU2AfraderpzOPAhCBYEGJEKyn\njF6BTwgWlCiCtevVNb0ClxAsKJEHK+/VuecAiEOwoMQuWPebzebLuecAiEOwoMRmk/dqs+E7\nhOATggUl8ljd5efczz0IQBSCBSXyXm3zV4W3554EIAbBghJFr4ofI/x27lEAIhAsKHF4p/v1\nZsMbG8AhBAtKHIL1km0uzjsJQAyCBSWOP0v4uNl8OOskADEIFpQ4/baGL5zGAocQLChR+n1Y\nHziNBf4gWFCi/BtHL/gJHXAHwYIS5WA97d/jAOAHggUAMhAsAJCBYAGADAQLAGQgWAAgA8EC\nABkIFgDIQLAAQAaCBQAyECwAkIFgAYAMBAsAZCBYACADwQIAGf5/pN5lnMo/LfsAAAAASUVO\nRK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 600,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(ggplot2)\n",
    "\n",
    "K_list <- c(1:50)\n",
    "knn_dist1_score <- numeric(length(K_list))\n",
    "knn_dist2_score <- numeric(length(K_list))\n",
    "\n",
    "idx <- sample(1:data[, .N], size = round(data[, .N]*.2))\n",
    "data_train <- data[-idx]\n",
    "data_test <- data[idx]\n",
    "\n",
    "for (k in K_list) {\n",
    "    model1 <- kknn(\"R1 ~ .\", data_train, data_test, distance = 1, k = k, kernel = \"rectangular\", scale = TRUE)\n",
    "    model2 <- kknn(\"R1 ~ .\", data_train, data_test, distance = 2, k = k, kernel = \"rectangular\", scale = TRUE)\n",
    "    knn_dist1_score[k] <- (((model1[['fitted.values']]+0.5) %>% floor) == data[idx, R1]) %>% mean\n",
    "    knn_dist2_score[k] <- (((model2[['fitted.values']]+0.5) %>% floor) == data[idx, R1]) %>% mean\n",
    "}\n",
    "\n",
    "# melt for the sake of ggplot\n",
    "knn_score = data.table(\n",
    "    k = K_list,\n",
    "    Manhattan = knn_dist1_score,\n",
    "    Euclidean = knn_dist2_score\n",
    ") %>% melt(., id.vars = \"k\", measure.vars = c(\"Manhattan\", \"Euclidean\"))\n",
    "\n",
    "options(repr.plot.width=10, repr.plot.height=10)\n",
    "ggplot() + \n",
    "    geom_line(data=knn_score, aes(x=k, y=value, color=variable), alpha=.5,size=1) +\n",
    "    ggtitle(\"KNN accuracy\") + \n",
    "    labs(y=\"Accuracy\", x=\"K\", color=\"distance metric\") + \n",
    "    theme(text = element_text(size=16), plot.title = element_text(hjust = 0.5, face=\"bold\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T15:13:14.147722Z",
     "start_time": "2021-01-18T15:13:14.091Z"
    }
   },
   "source": [
    "#### Leave-one-out CV\n",
    "\n",
    "Given the small data size, to utilize the information in training, one can also apply a leave-one-out CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T03:18:58.124415Z",
     "start_time": "2021-01-28T03:12:15.173Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAASwCAMAAADc/0P9AAAAe1BMVEUAAAAzMzNNTU1oaGh1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\nAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 600,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "one_off_CV <- function(k, data) {\n",
    "    N <- data[, .N]\n",
    "    knn_dist1_score_k <- numeric(N)\n",
    "    knn_dist2_score_k <- numeric(N)\n",
    "    for (i in 1:N) {\n",
    "        model1 <- kknn(\"R1 ~ .\", data[-i], data[i], distance = 1, k = k, kernel = \"rectangular\", scale = TRUE)\n",
    "        model2 <- kknn(\"R1 ~ .\", data[-i], data[i], distance = 2, k = k, kernel = \"rectangular\", scale = TRUE)\n",
    "        knn_dist1_score_k[i] <- (((model1[['fitted.values']]+0.5) %>% floor) == data[i, R1]) %>% as.numeric\n",
    "        knn_dist2_score_k[i] <- (((model2[['fitted.values']]+0.5) %>% floor) == data[i, R1]) %>% as.numeric\n",
    "    }\n",
    "    return(c(knn_dist1_score_k %>% mean, knn_dist2_score_k %>% mean))\n",
    "}\n",
    "\n",
    "K_list <- c(1:50)\n",
    "knn_dist1_score <- numeric(length(K_list))\n",
    "knn_dist2_score <- numeric(length(K_list))\n",
    "\n",
    "for (k in K_list) {\n",
    "    knn_score_k <- one_off_CV(k, data)\n",
    "    knn_dist1_score[k] <- knn_score_k[1]\n",
    "    knn_dist2_score[k] <- knn_score_k[2]\n",
    "}\n",
    "\n",
    "# melt for the sake of ggplot\n",
    "knn_score = data.table(\n",
    "    k = K_list,\n",
    "    Manhattan = knn_dist1_score,\n",
    "    Euclidean = knn_dist2_score\n",
    ") %>% melt(., id.vars = \"k\", measure.vars = c(\"Manhattan\", \"Euclidean\"))\n",
    "\n",
    "options(repr.plot.width=10, repr.plot.height=10)\n",
    "ggplot() + \n",
    "    geom_line(data=knn_score, aes(x=k, y=value, color=variable), alpha=.5,size=1) +\n",
    "    ggtitle(\"KNN accuracy\") + \n",
    "    labs(y=\"Accuracy\", x=\"K\", color=\"distance metric\") + \n",
    "    theme(text = element_text(size=16), plot.title = element_text(hjust = 0.5, face=\"bold\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T03:18:58.147506Z",
     "start_time": "2021-01-28T03:12:15.174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    variable optimal_K max_accuracy\n",
      "1: Manhattan        49    0.8654434\n",
      "2: Euclidean        39    0.8654434\n"
     ]
    }
   ],
   "source": [
    "print(knn_score[, .(optimal_K = which.max(value), max_accuracy = max(value)), by=.(variable)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-Parameter tuning\n",
    "\n",
    "We see that hyper-parameters apart from $K$ also matter. For example, as $K$ increases the Euclidean metric is able to generate more improvment than the Manhattan distance. We would like to finetune other parameters, including kernel. The `train.knn` function allows us to tune `K` and `kernel` jointly under the leave-one-out CV. We choose `distance=2` according to our observation above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T03:18:58.831804Z",
     "start_time": "2021-01-28T03:12:15.192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      "train.kknn(formula = \"R1 ~ .\", data = data, kmax = 100, distance = 2,     kernel = c(\"optimal\", \"rectangular\", \"triangular\", \"epanechnikov\",         \"gaussian\"), scale = TRUE)\n",
      "\n",
      "Type of response variable: continuous\n",
      "minimal mean absolute error: 0.1834862\n",
      "Minimal mean squared error: 0.1007652\n",
      "Best kernel: rectangular\n",
      "Best k: 58\n"
     ]
    }
   ],
   "source": [
    "N <- data[, .N]\n",
    "idx <- sample(1:N, size = round(N*.5), replace = FALSE)\n",
    "\n",
    "trained_model <- train.kknn(\"R1 ~ .\", data, kmax = 100, scale = TRUE, distance = 2, kernel = c(\"optimal\", \"rectangular\", \"triangular\", \"epanechnikov\", \"gaussian\"))\n",
    "print(trained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- [A User’s Guide to Support Vector Machines](http://pyml.sourceforge.net/doc/howto.pdf)\n",
    "- [A note from Boni Bruno](https://rstudio-pubs-static.s3.amazonaws.com/349520_6c62f724297f4084abb48493c6f703a5.html)\n",
    "    - Boni is likely a previous student. I contacted TA and Prof. as per the course policy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
